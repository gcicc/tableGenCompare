# Import required libraries for CTAB-GAN+ optimization
import optuna
import numpy as np
from src.models.model_factory import ModelFactory
from src.evaluation.trts_framework import TRTSEvaluator

# CTAB-GAN+ Search Space and Hyperparameter Optimization
# Note: CTAB-GAN+ has enhanced parameter support compared to CTAB-GAN

def ctabganplus_search_space(trial):
    """Define CTAB-GAN+ hyperparameter search space with enhanced capabilities."""
    return {
        'epochs': trial.suggest_int('epochs', 150, 600, step=50),  # Higher range for enhanced version
        'batch_size': trial.suggest_categorical('batch_size', [64, 128, 256, 512]),  # Additional option
        'test_ratio': trial.suggest_uniform('test_ratio', 0.15, 0.30),  # Wider range
    }

def ctabganplus_objective(trial):
    """CTAB-GAN+ objective function using ModelFactory."""
    try:
        # Get hyperparameters from trial
        params = ctabganplus_search_space(trial)
        
        print(f"\nüîÑ CTAB-GAN+ Trial {trial.number + 1}: epochs={params['epochs']}, batch_size={params['batch_size']}")
        
        # Initialize CTAB-GAN+ using ModelFactory
        model = ModelFactory.create("ctabganplus", random_state=42)
        
        # Train model with hyperparameters
        result = model.train(data, **params)
        
        print(f"üèãÔ∏è Training CTAB-GAN+...")
        
        # Generate synthetic data for evaluation
        synthetic_data = model.generate(len(data))
        
        # Calculate similarity score using TRTS framework
        trts = TRTSEvaluator(random_state=42)
        trts_results = trts.evaluate_trts_scenarios(data, synthetic_data, target_column="diagnosis")
        
        # Use TRTS score as similarity metric (average of all TRTS scenarios)
        trts_scores = [score for score in trts_results.values() if isinstance(score, (int, float))]
        similarity_score = np.mean(trts_scores) if trts_scores else 0.5
        
        # Calculate accuracy if applicable (for classification problems)
        try:
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.metrics import accuracy_score
            from sklearn.model_selection import train_test_split
            
            # Use last column as target for simple evaluation
            if len(data.columns) > 1:
                X_real, y_real = data.iloc[:, :-1], data.iloc[:, -1]
                X_synth, y_synth = synthetic_data.iloc[:, :-1], synthetic_data.iloc[:, -1]
                
                # Train on synthetic, test on real (TRTS approach)
                X_train, X_test, y_train, y_test = train_test_split(X_real, y_real, test_size=0.2, random_state=42)
                
                clf = RandomForestClassifier(random_state=42, n_estimators=50)
                clf.fit(X_synth, y_synth)
                
                predictions = clf.predict(X_test)
                accuracy = accuracy_score(y_test, predictions)
                
                # Combined score (weighted average of similarity and accuracy)
                score = 0.6 * similarity_score + 0.4 * accuracy
            else:
                score = similarity_score
                
        except:
            score = similarity_score
        
        print(f"‚úÖ CTAB-GAN+ Trial {trial.number + 1} Score: {score:.4f} (Similarity: {similarity_score:.4f})")
        
        return score
        
    except Exception as e:
        print(f"‚ùå CTAB-GAN+ trial {trial.number + 1} failed: {str(e)}")
        return 0.0

# Execute CTAB-GAN+ hyperparameter optimization
print("\nüéØ Starting CTAB-GAN+ Hyperparameter Optimization")
print("   ‚Ä¢ Search space: Limited parameters (CTAB-GAN+ constrains most hyperparameters)")
print("   ‚Ä¢ Number of trials: 10")
print(f"   ‚Ä¢ Algorithm: TPE with median pruning")

# Create and execute study
ctabganplus_study = optuna.create_study(direction="maximize", pruner=optuna.pruners.MedianPruner())
ctabganplus_study.optimize(ctabganplus_objective, n_trials=10)

# Display results
print(f"\n‚úÖ CTAB-GAN+ Optimization Complete:")
print(f"   ‚Ä¢ Best objective score: {ctabganplus_study.best_value:.4f}")
print(f"   ‚Ä¢ Best hyperparameters:")
for key, value in ctabganplus_study.best_params.items():
    if isinstance(value, float):
        print(f"     - {key}: {value:.4f}")
    else:
        print(f"     - {key}: {value}")

# Store best parameters for later use
ctabganplus_best_params = ctabganplus_study.best_params
print("\nüìä CTAB-GAN+ hyperparameter optimization completed successfully!")