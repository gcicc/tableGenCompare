{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Model Synthetic Data Generation: Breast Cancer Dataset\n",
    "\n",
    "## Comprehensive Demo and Hyperparameter Tuning of 5 Models\n",
    "\n",
    "This notebook demonstrates and hypertunesall 5 available models:\n",
    "1. **CTGAN** - Conditional Tabular GAN\n",
    "2. **TVAE** - Tabular Variational AutoEncoder  \n",
    "3. **CopulaGAN** - Copula-based GAN\n",
    "4. **GANerAid** - Enhanced GAN with clinical focus\n",
    "5. **TableGAN** - Table-specific GAN implementation\n",
    "\n",
    "### Methodology:\n",
    "1. **Phase 1**: Demo each model with default parameters\n",
    "2. **Phase 2**: Hypertune each model individually\n",
    "3. **Phase 3**: Identify best hyperparameters per model\n",
    "4. **Phase 4**: Re-tune best models with optimal parameters\n",
    "5. **Phase 5**: Compare all models and identify overall best\n",
    "6. **Phase 6**: Comprehensive analysis and visualizations\n",
    "\n",
    "### Dataset: Breast Cancer Wisconsin (Diagnostic)\n",
    "- **Features**: 5 continuous variables + 1 binary target\n",
    "- **Target**: Diagnosis (0=benign, 1=malignant)\n",
    "- **Samples**: 569 rows\n",
    "- **Use Case**: Medical diagnosis classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multi-model framework imported successfully\n",
      "‚úÖ CTGAN available\n",
      "‚úÖ TVAE available\n",
      "‚úÖ CopulaGAN available\n",
      "‚úÖ GANerAid available\n",
      "‚úÖ TableGAN available\n",
      "‚úÖ Optuna optimization available\n",
      "\n",
      "üìä MULTI-MODEL FRAMEWORK STATUS:\n",
      "‚úÖ Available models (5): CTGAN, TVAE, CopulaGAN, GANerAid, TableGAN\n",
      "\n",
      "üìÅ Results directory: c:\\Users\\gcicc\\claudeproj\\tableGenCompare\\results\\multi_model_analysis\n",
      "üìä Export settings - Figures: True, Tables: True\n",
      "üîß Optimization framework: Optuna\n"
     ]
    }
   ],
   "source": [
    "# Enhanced imports for multi-model analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# Model imports\n",
    "try:\n",
    "    from src.models.model_factory import ModelFactory\n",
    "    from src.evaluation.unified_evaluator import UnifiedEvaluator\n",
    "    from src.optimization.optuna_optimizer import OptunaOptimizer\n",
    "    FRAMEWORK_AVAILABLE = True\n",
    "    print(\"‚úÖ Multi-model framework imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Framework import failed: {e}\")\n",
    "    print(\"üìã Will use individual model imports\")\n",
    "    FRAMEWORK_AVAILABLE = False\n",
    "\n",
    "# Individual model imports as fallback\n",
    "MODEL_STATUS = {}\n",
    "\n",
    "# CTGAN\n",
    "try:\n",
    "    from src.models.implementations.ctgan_model import CTGANModel\n",
    "    MODEL_STATUS['CTGAN'] = True\n",
    "    print(\"‚úÖ CTGAN available\")\n",
    "except ImportError:\n",
    "    MODEL_STATUS['CTGAN'] = False\n",
    "    print(\"‚ö†Ô∏è CTGAN not available\")\n",
    "\n",
    "# TVAE\n",
    "try:\n",
    "    from src.models.implementations.tvae_model import TVAEModel\n",
    "    MODEL_STATUS['TVAE'] = True\n",
    "    print(\"‚úÖ TVAE available\")\n",
    "except ImportError:\n",
    "    MODEL_STATUS['TVAE'] = False\n",
    "    print(\"‚ö†Ô∏è TVAE not available\")\n",
    "\n",
    "# CopulaGAN\n",
    "try:\n",
    "    from src.models.implementations.copulagan_model import CopulaGANModel\n",
    "    MODEL_STATUS['CopulaGAN'] = True\n",
    "    print(\"‚úÖ CopulaGAN available\")\n",
    "except ImportError:\n",
    "    MODEL_STATUS['CopulaGAN'] = False\n",
    "    print(\"‚ö†Ô∏è CopulaGAN not available\")\n",
    "\n",
    "# GANerAid\n",
    "try:\n",
    "    from src.models.implementations.ganeraid_model import GANerAidModel\n",
    "    MODEL_STATUS['GANerAid'] = True\n",
    "    print(\"‚úÖ GANerAid available\")\n",
    "except ImportError:\n",
    "    MODEL_STATUS['GANerAid'] = False\n",
    "    print(\"‚ö†Ô∏è GANerAid not available\")\n",
    "\n",
    "# TableGAN\n",
    "try:\n",
    "    from src.models.implementations.tablegan_model import TableGANModel\n",
    "    MODEL_STATUS['TableGAN'] = True\n",
    "    print(\"‚úÖ TableGAN available\")\n",
    "except ImportError:\n",
    "    MODEL_STATUS['TableGAN'] = False\n",
    "    print(\"‚ö†Ô∏è TableGAN not available\")\n",
    "\n",
    "# Optimization framework\n",
    "try:\n",
    "    import optuna\n",
    "    from optuna.samplers import TPESampler\n",
    "    OPTUNA_AVAILABLE = True\n",
    "    print(\"‚úÖ Optuna optimization available\")\n",
    "except ImportError:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Optuna not available - will use basic grid search\")\n",
    "\n",
    "# Evaluation libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy import stats\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = Path('results/multi_model_analysis')\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export configuration\n",
    "EXPORT_FIGURES = True\n",
    "EXPORT_TABLES = True\n",
    "FIGURE_FORMAT = 'png'\n",
    "FIGURE_DPI = 300\n",
    "\n",
    "print(f\"\\nüìä MULTI-MODEL FRAMEWORK STATUS:\")\n",
    "available_models = [model for model, status in MODEL_STATUS.items() if status]\n",
    "unavailable_models = [model for model, status in MODEL_STATUS.items() if not status]\n",
    "\n",
    "print(f\"‚úÖ Available models ({len(available_models)}): {', '.join(available_models)}\")\n",
    "if unavailable_models:\n",
    "    print(f\"‚ö†Ô∏è Unavailable models ({len(unavailable_models)}): {', '.join(unavailable_models)}\")\n",
    "\n",
    "print(f\"\\nüìÅ Results directory: {RESULTS_DIR.absolute()}\")\n",
    "print(f\"üìä Export settings - Figures: {EXPORT_FIGURES}, Tables: {EXPORT_TABLES}\")\n",
    "print(f\"üîß Optimization framework: {'Optuna' if OPTUNA_AVAILABLE else 'Basic Grid Search'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LOADING Breast Cancer Wisconsin (Diagnostic)\n",
      "==================================================\n",
      "‚úÖ Data loaded successfully: (569, 6)\n",
      "\n",
      "üìã Dataset Overview:\n",
      "   ‚Ä¢ Shape: 569 rows √ó 6 columns\n",
      "   ‚Ä¢ Missing values: 0\n",
      "   ‚Ä¢ Duplicate rows: 0\n",
      "   ‚Ä¢ Memory usage: 0.03 MB\n",
      "\n",
      "üéØ Target Variable (diagnosis):\n",
      "   ‚Ä¢ Benign (0): 212 samples (37.3%)\n",
      "   ‚Ä¢ Malignant (1): 357 samples (62.7%)\n",
      "   ‚Ä¢ Balance ratio: 0.594 (Moderately Imbalanced)\n",
      "\n",
      "üîß Preprocessing data...\n",
      "   ‚Ä¢ No missing values to handle\n",
      "   ‚Ä¢ No duplicates to remove\n",
      "   ‚Ä¢ Optimizing data types\n",
      "\n",
      "‚úÖ Preprocessing completed: (569, 6)\n",
      "üìã Final dataset ready for multi-model analysis\n",
      "\n",
      "üìã Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.990000</td>\n",
       "      <td>10.380000</td>\n",
       "      <td>122.800003</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.570000</td>\n",
       "      <td>17.770000</td>\n",
       "      <td>132.899994</td>\n",
       "      <td>1326.000000</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.690001</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1203.000000</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.420000</td>\n",
       "      <td>20.379999</td>\n",
       "      <td>77.580002</td>\n",
       "      <td>386.100006</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.290001</td>\n",
       "      <td>14.340000</td>\n",
       "      <td>135.100006</td>\n",
       "      <td>1297.000000</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter    mean_area  mean_smoothness  \\\n",
       "0    17.990000     10.380000      122.800003  1001.000000          0.11840   \n",
       "1    20.570000     17.770000      132.899994  1326.000000          0.08474   \n",
       "2    19.690001     21.250000      130.000000  1203.000000          0.10960   \n",
       "3    11.420000     20.379999       77.580002   386.100006          0.14250   \n",
       "4    20.290001     14.340000      135.100006  1297.000000          0.10030   \n",
       "\n",
       "   diagnosis  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Preprocessed data exported: results\\multi_model_analysis\\preprocessed_breast_cancer_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess breast cancer data\n",
    "DATA_FILE = \"data/Breast_cancer_data.csv\"\n",
    "TARGET_COLUMN = \"diagnosis\"\n",
    "DATASET_NAME = \"Breast Cancer Wisconsin (Diagnostic)\"\n",
    "\n",
    "print(f\"üìä LOADING {DATASET_NAME}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Load data\n",
    "    data = pd.read_csv(DATA_FILE)\n",
    "    print(f\"‚úÖ Data loaded successfully: {data.shape}\")\n",
    "    \n",
    "    # Basic data info\n",
    "    print(f\"\\nüìã Dataset Overview:\")\n",
    "    print(f\"   ‚Ä¢ Shape: {data.shape[0]} rows √ó {data.shape[1]} columns\")\n",
    "    print(f\"   ‚Ä¢ Missing values: {data.isnull().sum().sum()}\")\n",
    "    print(f\"   ‚Ä¢ Duplicate rows: {data.duplicated().sum()}\")\n",
    "    print(f\"   ‚Ä¢ Memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Target analysis\n",
    "    if TARGET_COLUMN in data.columns:\n",
    "        target_counts = data[TARGET_COLUMN].value_counts().sort_index()\n",
    "        print(f\"\\nüéØ Target Variable ({TARGET_COLUMN}):\")\n",
    "        for value, count in target_counts.items():\n",
    "            percentage = (count / len(data)) * 100\n",
    "            label = 'Benign' if value == 0 else 'Malignant' if value == 1 else f'Class {value}'\n",
    "            print(f\"   ‚Ä¢ {label} ({value}): {count} samples ({percentage:.1f}%)\")\n",
    "        \n",
    "        balance_ratio = target_counts.min() / target_counts.max()\n",
    "        balance_status = 'Balanced' if balance_ratio > 0.8 else 'Moderately Imbalanced' if balance_ratio > 0.5 else 'Highly Imbalanced'\n",
    "        print(f\"   ‚Ä¢ Balance ratio: {balance_ratio:.3f} ({balance_status})\")\n",
    "    \n",
    "    # Data preprocessing\n",
    "    print(f\"\\nüîß Preprocessing data...\")\n",
    "    processed_data = data.copy()\n",
    "    \n",
    "    # Handle missing values (if any)\n",
    "    missing_counts = processed_data.isnull().sum()\n",
    "    if missing_counts.sum() > 0:\n",
    "        print(f\"   ‚Ä¢ Handling {missing_counts.sum()} missing values\")\n",
    "        for col in missing_counts[missing_counts > 0].index:\n",
    "            if processed_data[col].dtype in ['int64', 'float64']:\n",
    "                processed_data[col].fillna(processed_data[col].median(), inplace=True)\n",
    "            else:\n",
    "                processed_data[col].fillna(processed_data[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ No missing values to handle\")\n",
    "    \n",
    "    # Remove duplicates (if any)\n",
    "    duplicates = processed_data.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        processed_data = processed_data.drop_duplicates()\n",
    "        print(f\"   ‚Ä¢ Removed {duplicates} duplicate rows\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ No duplicates to remove\")\n",
    "    \n",
    "    # Data type optimization\n",
    "    print(f\"   ‚Ä¢ Optimizing data types\")\n",
    "    for col in processed_data.select_dtypes(include=['int64']).columns:\n",
    "        processed_data[col] = pd.to_numeric(processed_data[col], downcast='integer')\n",
    "    for col in processed_data.select_dtypes(include=['float64']).columns:\n",
    "        processed_data[col] = pd.to_numeric(processed_data[col], downcast='float')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Preprocessing completed: {processed_data.shape}\")\n",
    "    print(f\"üìã Final dataset ready for multi-model analysis\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(f\"\\nüìã Sample data:\")\n",
    "    display(processed_data.head())\n",
    "    \n",
    "    # Export preprocessed data\n",
    "    if EXPORT_TABLES:\n",
    "        processed_data.to_csv(RESULTS_DIR / 'preprocessed_breast_cancer_data.csv', index=False)\n",
    "        print(f\"üíæ Preprocessed data exported: {RESULTS_DIR / 'preprocessed_breast_cancer_data.csv'}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Could not find file {DATA_FILE}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Demo All Models with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ PHASE 1: DEMO ALL MODELS WITH DEFAULT PARAMETERS\n",
      "============================================================\n",
      "üìä Demo Configuration:\n",
      "   ‚Ä¢ Training epochs: 100\n",
      "   ‚Ä¢ Samples to generate: 569\n",
      "   ‚Ä¢ Models to demo: 5\n",
      "\n",
      "üéØ Starting model demonstrations...\n",
      "\n",
      "[1/5] üîß CTGAN\n",
      "----------------------------------------\n",
      "üìä Parameters:\n",
      "   ‚Ä¢ epochs: 100\n",
      "   ‚Ä¢ batch_size: 500\n",
      "   ‚Ä¢ generator_lr: 2.00e-04\n",
      "   ‚Ä¢ discriminator_lr: 2.00e-04\n",
      "üöÄ Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.86) | Discrim. (-0.08): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 30.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete: 10.28s\n",
      "üé≤ Generating 569 samples...\n",
      "‚úÖ Generation complete: 0.028s\n",
      "üìä Output shape: (569, 6)\n",
      "‚úÖ CTGAN demo successful (10.31s total)\n",
      "\n",
      "[2/5] üîß TVAE\n",
      "----------------------------------------\n",
      "üìä Parameters:\n",
      "   ‚Ä¢ epochs: 100\n",
      "   ‚Ä¢ batch_size: 500\n",
      "   ‚Ä¢ learning_rate: 0.0010\n",
      "üöÄ Training...\n",
      "‚úÖ Training complete: 6.49s\n",
      "üé≤ Generating 569 samples...\n",
      "‚úÖ Generation complete: 0.040s\n",
      "üìä Output shape: (569, 6)\n",
      "‚úÖ TVAE demo successful (6.54s total)\n",
      "\n",
      "[3/5] üîß COPULAGAN\n",
      "----------------------------------------\n",
      "üìä Parameters:\n",
      "   ‚Ä¢ epochs: 100\n",
      "   ‚Ä¢ batch_size: 500\n",
      "   ‚Ä¢ generator_lr: 2.00e-04\n",
      "   ‚Ä¢ discriminator_lr: 2.00e-04\n",
      "üöÄ Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s, loss=d error: 1.3855732083320618 --- g error 0.695507287979126]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete: 7.36s\n",
      "üé≤ Generating 569 samples...\n",
      "‚úÖ Generation complete: 0.079s\n",
      "üìä Output shape: (569, 6)\n",
      "‚úÖ CopulaGAN demo successful (7.43s total)\n",
      "\n",
      "[4/5] üîß GANERAID\n",
      "----------------------------------------\n",
      "üìä Parameters:\n",
      "   ‚Ä¢ epochs: 100\n",
      "   ‚Ä¢ batch_size: 100\n",
      "   ‚Ä¢ lr_g: 5.00e-04\n",
      "   ‚Ä¢ lr_d: 5.00e-04\n",
      "üöÄ Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 24.81it/s, loss=d error: 1.3380348980426788 --- g error 0.9733946323394775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training complete: 4.07s\n",
      "üé≤ Generating 569 samples...\n",
      "‚úÖ Generation complete: 0.102s\n",
      "üìä Output shape: (569, 6)\n",
      "‚úÖ GANerAid demo successful (4.18s total)\n",
      "\n",
      "[5/5] üîß TABLEGAN\n",
      "----------------------------------------\n",
      "üìä Parameters:\n",
      "   ‚Ä¢ epochs: 100\n",
      "   ‚Ä¢ batch_size: 32\n",
      "   ‚Ä¢ lr: 2.00e-04\n",
      "üöÄ Training...\n",
      "‚úÖ Training complete: 13.58s\n",
      "üé≤ Generating 569 samples...\n",
      "‚úÖ Generation complete: 0.003s\n",
      "üìä Output shape: (569, 6)\n",
      "‚úÖ TableGAN demo successful (13.59s total)\n",
      "\n",
      "üìä PHASE 1 SUMMARY\n",
      "=========================\n",
      "‚úÖ Successful: 5/5 models\n",
      "   Models: CTGAN, TVAE, CopulaGAN, GANerAid, TableGAN\n",
      "\n",
      "‚è±Ô∏è Performance Summary:\n",
      "   ‚Ä¢   GANerAid:    4.1s train,  0.102s generate\n",
      "   ‚Ä¢       TVAE:    6.5s train,  0.040s generate\n",
      "   ‚Ä¢  CopulaGAN:    7.4s train,  0.079s generate\n",
      "   ‚Ä¢      CTGAN:   10.3s train,  0.028s generate\n",
      "   ‚Ä¢   TableGAN:   13.6s train,  0.003s generate\n",
      "\n",
      "üéØ Phase 1 completed. Proceeding to hyperparameter tuning.\n"
     ]
    }
   ],
   "source": [
    "# Phase 1: Demo all available models with default parameters - HARMONIZED OUTPUT\n",
    "print(\"üöÄ PHASE 1: DEMO ALL MODELS WITH DEFAULT PARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize results storage\n",
    "phase1_results = {}\n",
    "phase1_synthetic_data = {}\n",
    "phase1_training_times = {}\n",
    "phase1_generation_times = {}\n",
    "\n",
    "# Demo configuration\n",
    "DEMO_EPOCHS = 100  # Reduced for demo purposes\n",
    "DEMO_SAMPLES = len(processed_data)\n",
    "\n",
    "print(f\"üìä Demo Configuration:\")\n",
    "print(f\"   ‚Ä¢ Training epochs: {DEMO_EPOCHS:,}\")\n",
    "print(f\"   ‚Ä¢ Samples to generate: {DEMO_SAMPLES:,}\")\n",
    "print(f\"   ‚Ä¢ Models to demo: {len(available_models)}\")\n",
    "print(f\"\\nüéØ Starting model demonstrations...\\n\")\n",
    "\n",
    "# Helper function to format parameter values consistently\n",
    "def format_param_value(value):\n",
    "    \"\"\"Format parameter values consistently across all models\"\"\"\n",
    "    if isinstance(value, float):\n",
    "        if value < 0.001:\n",
    "            return f\"{value:.2e}\"\n",
    "        elif value < 1:\n",
    "            return f\"{value:.4f}\"\n",
    "        else:\n",
    "            return f\"{value:.3f}\"\n",
    "    elif isinstance(value, tuple):\n",
    "        return f\"({', '.join(str(v) for v in value)})\"\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "for model_idx, model_name in enumerate(available_models, 1):\n",
    "    print(f\"[{model_idx}/{len(available_models)}] üîß {model_name.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        demo_start = time.time()\n",
    "        \n",
    "        # Initialize model with default parameters\n",
    "        if model_name == 'CTGAN':\n",
    "            model = CTGANModel()\n",
    "            train_params = {\n",
    "                'epochs': DEMO_EPOCHS,\n",
    "                'batch_size': 500,\n",
    "                'discriminator_lr': 2e-4,\n",
    "                'generator_lr': 2e-4,\n",
    "                'discriminator_decay': 1e-6,\n",
    "                'generator_decay': 1e-6\n",
    "            }\n",
    "            \n",
    "        elif model_name == 'TVAE':\n",
    "            model = TVAEModel()\n",
    "            train_params = {\n",
    "                'epochs': DEMO_EPOCHS,\n",
    "                'batch_size': 500,\n",
    "                'compress_dims': (128, 128),\n",
    "                'decompress_dims': (128, 128),\n",
    "                'l2scale': 1e-5,\n",
    "                'learning_rate': 1e-3\n",
    "            }\n",
    "            \n",
    "        elif model_name == 'CopulaGAN':\n",
    "            model = CopulaGANModel()\n",
    "            train_params = {\n",
    "                'epochs': DEMO_EPOCHS,\n",
    "                'batch_size': 500,\n",
    "                'discriminator_lr': 2e-4,\n",
    "                'generator_lr': 2e-4,\n",
    "                'discriminator_decay': 1e-6,\n",
    "                'generator_decay': 1e-6\n",
    "            }\n",
    "            \n",
    "        elif model_name == 'GANerAid':\n",
    "            model = GANerAidModel()\n",
    "            train_params = {\n",
    "                'epochs': DEMO_EPOCHS,\n",
    "                'lr_d': 0.0005,\n",
    "                'lr_g': 0.0005,\n",
    "                'hidden_feature_space': 200,\n",
    "                'batch_size': 100,\n",
    "                'nr_of_rows': 25,\n",
    "                'binary_noise': 0.2\n",
    "            }\n",
    "            \n",
    "        elif model_name == 'TableGAN':\n",
    "            model = TableGANModel()\n",
    "            train_params = {\n",
    "                'epochs': DEMO_EPOCHS,\n",
    "                'batch_size': 32,\n",
    "                'lr': 0.0002,\n",
    "                'beta1': 0.5,\n",
    "                'beta2': 0.999\n",
    "            }\n",
    "        \n",
    "        # Display parameters in consistent format\n",
    "        print(f\"üìä Parameters:\")\n",
    "        key_params = ['epochs', 'batch_size']\n",
    "        if 'lr' in train_params:\n",
    "            key_params.append('lr')\n",
    "        elif 'learning_rate' in train_params:\n",
    "            key_params.append('learning_rate')\n",
    "        elif 'generator_lr' in train_params:\n",
    "            key_params.extend(['generator_lr', 'discriminator_lr'])\n",
    "        elif 'lr_g' in train_params:\n",
    "            key_params.extend(['lr_g', 'lr_d'])\n",
    "            \n",
    "        for param in key_params:\n",
    "            if param in train_params:\n",
    "                print(f\"   ‚Ä¢ {param}: {format_param_value(train_params[param])}\")\n",
    "        \n",
    "        # Train model with suppressed verbose output\n",
    "        print(f\"üöÄ Training...\")\n",
    "        training_start = time.time()\n",
    "        \n",
    "        # Suppress model-specific verbose output\n",
    "        import sys\n",
    "        from io import StringIO\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = mystdout = StringIO()\n",
    "        \n",
    "        try:\n",
    "            model.train(processed_data, **train_params)\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "        \n",
    "        training_end = time.time()\n",
    "        training_time = training_end - training_start\n",
    "        phase1_training_times[model_name] = training_time\n",
    "        \n",
    "        print(f\"‚úÖ Training complete: {training_time:.2f}s\")\n",
    "        \n",
    "        # Generate synthetic data\n",
    "        print(f\"üé≤ Generating {DEMO_SAMPLES:,} samples...\")\n",
    "        generation_start = time.time()\n",
    "        \n",
    "        # Suppress generation output too\n",
    "        sys.stdout = mystdout = StringIO()\n",
    "        try:\n",
    "            synthetic_data = model.generate(DEMO_SAMPLES)\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "        \n",
    "        generation_end = time.time()\n",
    "        generation_time = generation_end - generation_start\n",
    "        phase1_generation_times[model_name] = generation_time\n",
    "        \n",
    "        print(f\"‚úÖ Generation complete: {generation_time:.3f}s\")\n",
    "        print(f\"üìä Output shape: {synthetic_data.shape}\")\n",
    "        \n",
    "        # Store results\n",
    "        phase1_synthetic_data[model_name] = synthetic_data\n",
    "        \n",
    "        demo_end = time.time()\n",
    "        total_demo_time = demo_end - demo_start\n",
    "        \n",
    "        phase1_results[model_name] = {\n",
    "            'status': 'success',\n",
    "            'training_time': training_time,\n",
    "            'generation_time': generation_time,\n",
    "            'total_time': total_demo_time,\n",
    "            'generated_samples': len(synthetic_data),\n",
    "            'parameters': train_params\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} demo successful ({total_demo_time:.2f}s total)\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"‚ùå {model_name} demo failed: {error_msg[:80]}...\")\n",
    "        phase1_results[model_name] = {\n",
    "            'status': 'failed',\n",
    "            'error': error_msg,\n",
    "            'training_time': 0,\n",
    "            'generation_time': 0,\n",
    "            'total_time': 0,\n",
    "            'generated_samples': 0\n",
    "        }\n",
    "        print(f\"‚è≠Ô∏è Continuing to next model...\\n\")\n",
    "\n",
    "# Phase 1 Summary\n",
    "print(f\"üìä PHASE 1 SUMMARY\")\n",
    "print(\"=\"*25)\n",
    "\n",
    "successful_models = [name for name, result in phase1_results.items() if result['status'] == 'success']\n",
    "failed_models = [name for name, result in phase1_results.items() if result['status'] == 'failed']\n",
    "\n",
    "print(f\"‚úÖ Successful: {len(successful_models)}/{len(available_models)} models\")\n",
    "if successful_models:\n",
    "    print(f\"   Models: {', '.join(successful_models)}\")\n",
    "if failed_models:\n",
    "    print(f\"‚ùå Failed: {len(failed_models)} models ({', '.join(failed_models)})\")\n",
    "\n",
    "if successful_models:\n",
    "    print(f\"\\n‚è±Ô∏è Performance Summary:\")\n",
    "    # Sort by training time for consistent ordering\n",
    "    sorted_by_time = sorted(successful_models, key=lambda x: phase1_results[x]['training_time'])\n",
    "    for model_name in sorted_by_time:\n",
    "        result = phase1_results[model_name]\n",
    "        print(f\"   ‚Ä¢ {model_name:>10}: {result['training_time']:>6.1f}s train, {result['generation_time']:>6.3f}s generate\")\n",
    "\n",
    "print(f\"\\nüéØ Phase 1 completed. Proceeding to hyperparameter tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Hyperparameter Tuning for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß PHASE 2: HYPERPARAMETER TUNING FOR EACH MODEL\n",
      "=======================================================\n",
      "üìä Hypertuning Configuration:\n",
      "   ‚Ä¢ Trials per model: 20\n",
      "   ‚Ä¢ Training epochs: 100\n",
      "   ‚Ä¢ Optimization metric: Combined similarity + utility score\n",
      "   ‚Ä¢ Models to tune: 5\n",
      "\n",
      "[1/5] üîß TUNING CTGAN\n",
      "----------------------------------------\n",
      "üìä Enhanced hyperparameter space: 10 parameters\n",
      "   Key parameters: epochs, batch_size, generator_lr, discriminator_lr, generator_dim\n",
      "   (+5 more parameters)\n",
      "üöÄ Optimizing with enhanced hyperparameter space...\n",
      "   Trial 1/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.89) | Discrim. (-0.35): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 28.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.56) | Discrim. (0.08): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.09) | Discrim. (-0.22): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 29.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.67) | Discrim. (-0.02): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.81) | Discrim. (-0.06): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.40) | Discrim. (-0.02): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 29.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.72) | Discrim. (-0.17): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.78) | Discrim. (-0.19): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.37) | Discrim. (-0.05): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 30.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial 10/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.56) | Discrim. (-0.05): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 30.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.75) | Discrim. (-0.10): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-1.09) | Discrim. (0.03): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 28.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.66) | Discrim. (-0.16): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.41) | Discrim. (0.07): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 28.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.38) | Discrim. (0.06): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-1.16) | Discrim. (0.00): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 30.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.90) | Discrim. (0.04): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-0.35) | Discrim. (0.08): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Gen. (-1.07) | Discrim. (-0.04): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial 20/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.90) | Discrim. (-0.12): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Enhanced optimization complete!\n",
      "üèÜ Best score: 0.8029\n",
      "   ‚Ä¢ Utility: 0.906\n",
      "   ‚Ä¢ Similarity: 0.648\n",
      "   ‚Ä¢ Hyperparameters optimized: 10\n",
      "   ‚Ä¢ Key optimized params: batch_size=256, discriminator_decay=8.96e-06, discriminator_dim=(512, 512)\n",
      "\n",
      "[2/5] üîß TUNING TVAE\n",
      "----------------------------------------\n",
      "üìä Enhanced hyperparameter space: 12 parameters\n",
      "   Key parameters: epochs, compress_dims, decompress_dims, l2scale, batch_size\n",
      "   (+7 more parameters)\n",
      "üöÄ Optimizing with enhanced hyperparameter space...\n",
      "   Trial 1/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........   Trial 10/20............   Trial 20/20...\n",
      "‚úÖ Enhanced optimization complete!\n",
      "üèÜ Best score: 0.9347\n",
      "   ‚Ä¢ Utility: 1.000\n",
      "   ‚Ä¢ Similarity: 0.837\n",
      "   ‚Ä¢ Hyperparameters optimized: 12\n",
      "   ‚Ä¢ Key optimized params: batch_size=64, beta=1.94, compress_dims=(64, 128, 64)\n",
      "\n",
      "[3/5] üîß TUNING COPULAGAN\n",
      "----------------------------------------\n",
      "üìä Enhanced hyperparameter space: 14 parameters\n",
      "   Key parameters: epochs, batch_size, generator_lr, discriminator_lr, generator_dim\n",
      "   (+9 more parameters)\n",
      "üöÄ Optimizing with enhanced hyperparameter space...\n",
      "   Trial 1/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial 10/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\tsrc.models.implementations.copulagan_model:copulagan_model.py:train()- CopulaGAN training failed: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial 20/20...\n",
      "‚úÖ Enhanced optimization complete!\n",
      "üèÜ Best score: 0.7623\n",
      "   ‚Ä¢ Utility: 0.819\n",
      "   ‚Ä¢ Similarity: 0.678\n",
      "   ‚Ä¢ Hyperparameters optimized: 14\n",
      "   ‚Ä¢ Key optimized params: batch_size=2000, beta1=0.597, beta2=0.998\n",
      "\n",
      "[4/5] üîß TUNING GANERAID\n",
      "----------------------------------------\n",
      "üìä Enhanced hyperparameter space: 15 parameters\n",
      "   Key parameters: epochs, lr_d, lr_g, hidden_feature_space, batch_size\n",
      "   (+10 more parameters)\n",
      "üöÄ Optimizing with enhanced hyperparameter space...\n",
      "   Trial 1/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 25.69it/s, loss=d error: 0.847705602645874 --- g error 1.3776053190231323]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 27.63it/s, loss=d error: 1.176948219537735 --- g error 1.6454113721847534]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 27.47it/s, loss=d error: 1.4663508534431458 --- g error 1.0045181512832642] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.17it/s, loss=d error: 1.1639469861984253 --- g error 1.3511860370635986] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.18it/s, loss=d error: 1.18215411901474 --- g error 1.6952650547027588]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.04it/s, loss=d error: 0.9156097769737244 --- g error 1.4811770915985107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.39it/s, loss=d error: 0.8628133833408356 --- g error 2.1517040729522705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:08<00:00, 23.51it/s, loss=d error: 0.8799825608730316 --- g error 2.2454490661621094] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 25.47it/s, loss=d error: 0.9644411504268646 --- g error 1.4464221000671387] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial 10/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.52it/s, loss=d error: 1.6499612927436829 --- g error 0.8520437479019165] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.52it/s, loss=d error: 0.5582468509674072 --- g error 2.1423542499542236] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 25.43it/s, loss=d error: 0.9773924648761749 --- g error 1.3066492080688477] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 25.08it/s, loss=d error: 0.7481895685195923 --- g error 2.4065756797790527] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 25.30it/s, loss=d error: 0.8017787039279938 --- g error 2.3208746910095215] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.95it/s, loss=d error: 0.7323077321052551 --- g error 3.625663995742798]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.83it/s, loss=d error: 1.75621497631073 --- g error 1.0994009971618652]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 25.43it/s, loss=d error: 0.7409707605838776 --- g error 1.891394853591919]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.07it/s, loss=d error: 0.9619266390800476 --- g error 2.207833766937256]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 27.62it/s, loss=d error: 0.8046680092811584 --- g error 1.3887803554534912] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial 20/20..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 27.03it/s, loss=d error: 0.9622973203659058 --- g error 1.4106390476226807] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Enhanced optimization complete!\n",
      "üèÜ Best score: 0.7878\n",
      "   ‚Ä¢ Utility: 0.846\n",
      "   ‚Ä¢ Similarity: 0.701\n",
      "   ‚Ä¢ Hyperparameters optimized: 15\n",
      "   ‚Ä¢ Key optimized params: batch_size=16, beta1=0.278, beta2=0.912\n",
      "\n",
      "[5/5] üîß TUNING TABLEGAN\n",
      "----------------------------------------\n",
      "üìä Enhanced hyperparameter space: 13 parameters\n",
      "   Key parameters: epochs, batch_size, learning_rate, noise_dim, generator_dims\n",
      "   (+8 more parameters)\n",
      "üöÄ Optimizing with enhanced hyperparameter space...\n",
      "   Trial 1/20...........   Trial 10/20............   Trial 20/20...\n",
      "‚úÖ Enhanced optimization complete!\n",
      "üèÜ Best score: 0.3665\n",
      "   ‚Ä¢ Utility: 0.001\n",
      "   ‚Ä¢ Similarity: 0.915\n",
      "   ‚Ä¢ Hyperparameters optimized: 13\n",
      "   ‚Ä¢ Key optimized params: batch_size=256, beta1=0.434, beta2=0.933\n",
      "\n",
      "üìä ENHANCED PHASE 2 SUMMARY\n",
      "===================================\n",
      "‚úÖ Successfully tuned: 5/5 models\n",
      "   Models: CTGAN, TVAE, CopulaGAN, GANerAid, TableGAN\n",
      "\n",
      "üèÜ Enhanced Optimization Results:\n",
      "   ‚Ä¢       TVAE: 0.9347 (12 params, TPE Bayesian)\n",
      "   ‚Ä¢      CTGAN: 0.8029 (10 params, TPE Bayesian)\n",
      "   ‚Ä¢   GANerAid: 0.7878 (15 params, TPE Bayesian)\n",
      "   ‚Ä¢  CopulaGAN: 0.7623 (14 params, TPE Bayesian)\n",
      "   ‚Ä¢   TableGAN: 0.3665 (13 params, TPE Bayesian)\n",
      "\n",
      "üìä Hyperparameter Space Summary:\n",
      "   ‚Ä¢ Total parameters across all models: 64\n",
      "   ‚Ä¢ Average parameters per model: 12.8\n",
      "   ‚Ä¢ Total optimization trials: 100\n",
      "\n",
      "üéØ Enhanced Phase 2 completed. Best model: TVAE with 12 optimized parameters\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Hyperparameter tuning for each successful model - ENHANCED WITH ROBUST SPACES\n",
    "print(\"üîß PHASE 2: HYPERPARAMETER TUNING FOR EACH MODEL\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "if not successful_models:\n",
    "    print(\"‚ö†Ô∏è No successful models from Phase 1. Cannot proceed with hypertuning.\")\n",
    "else:\n",
    "    # Initialize results storage\n",
    "    phase2_results = {}\n",
    "    phase2_best_params = {}\n",
    "    phase2_best_scores = {}\n",
    "    \n",
    "    # Hypertuning configuration - ENHANCED FOR ROBUSTNESS\n",
    "    N_TRIALS = 20  # Increased trials for better optimization\n",
    "    TUNE_EPOCHS = 100  # Increased epochs for better convergence\n",
    "    \n",
    "    print(f\"üìä Hypertuning Configuration:\")\n",
    "    print(f\"   ‚Ä¢ Trials per model: {N_TRIALS}\")\n",
    "    print(f\"   ‚Ä¢ Training epochs: {TUNE_EPOCHS}\")\n",
    "    print(f\"   ‚Ä¢ Optimization metric: Combined similarity + utility score\")\n",
    "    print(f\"   ‚Ä¢ Models to tune: {len(successful_models)}\")\n",
    "    \n",
    "    # Enhanced progress tracking for objective function with better error handling\n",
    "    def create_objective_function(model_name: str, model_class, current_trial_container):\n",
    "        \"\"\"Create objective function for hyperparameter optimization with progress tracking\"\"\"\n",
    "        \n",
    "        def objective(trial):\n",
    "            try:\n",
    "                current_trial_container[0] += 1\n",
    "                trial_num = current_trial_container[0]\n",
    "                \n",
    "                # Print minimal progress indicator every 10 trials\n",
    "                if trial_num % 10 == 0 or trial_num == 1:\n",
    "                    print(f\"   Trial {trial_num}/{N_TRIALS}...\", end='', flush=True)\n",
    "                elif trial_num == N_TRIALS:\n",
    "                    print(\" Complete!\")\n",
    "                else:\n",
    "                    print(\".\", end='', flush=True)\n",
    "                \n",
    "                # Initialize model and get enhanced hyperparameter space\n",
    "                model = model_class()\n",
    "                hyperparameter_space = model.get_hyperparameter_space()\n",
    "                \n",
    "                # Sample hyperparameters using the enhanced spaces\n",
    "                params = {}\n",
    "                \n",
    "                for param_name, param_config in hyperparameter_space.items():\n",
    "                    if param_config['type'] == 'float':\n",
    "                        if param_config.get('log', False):\n",
    "                            params[param_name] = trial.suggest_float(\n",
    "                                param_name, param_config['low'], param_config['high'], log=True\n",
    "                            )\n",
    "                        else:\n",
    "                            params[param_name] = trial.suggest_float(\n",
    "                                param_name, param_config['low'], param_config['high']\n",
    "                            )\n",
    "                    elif param_config['type'] == 'int':\n",
    "                        params[param_name] = trial.suggest_int(\n",
    "                            param_name, param_config['low'], param_config['high'], \n",
    "                            step=param_config.get('step', 1)\n",
    "                        )\n",
    "                    elif param_config['type'] == 'categorical':\n",
    "                        params[param_name] = trial.suggest_categorical(\n",
    "                            param_name, param_config['choices']\n",
    "                        )\n",
    "                \n",
    "                # Override epochs to control training time during optimization\n",
    "                if 'epochs' not in params:\n",
    "                    params['epochs'] = TUNE_EPOCHS\n",
    "                elif params['epochs'] > 200:  # Cap epochs during tuning for speed\n",
    "                    params['epochs'] = min(params['epochs'], 200)\n",
    "                \n",
    "                # Model-specific parameter handling\n",
    "                if model_name == 'CTGAN':\n",
    "                    # Ensure CTGAN uses the enhanced parameters properly\n",
    "                    if 'generator_lr' not in params and 'learning_rate' in params:\n",
    "                        params['generator_lr'] = params.pop('learning_rate')\n",
    "                    if 'discriminator_lr' not in params and 'generator_lr' in params:\n",
    "                        params['discriminator_lr'] = params['generator_lr']\n",
    "                \n",
    "                elif model_name == 'TVAE':\n",
    "                    # Handle TVAE's specific architecture parameters\n",
    "                    if 'learning_rate' not in params and 'lr' in params:\n",
    "                        params['learning_rate'] = params.pop('lr')\n",
    "                    \n",
    "                elif model_name == 'TableGAN':\n",
    "                    # TableGAN needs configuration before training\n",
    "                    config_params = {k: v for k, v in params.items() if k != 'epochs'}\n",
    "                    model.set_config(config_params)\n",
    "                \n",
    "                # Suppress all training/generation output during optimization\n",
    "                import sys\n",
    "                from io import StringIO\n",
    "                old_stdout = sys.stdout\n",
    "                sys.stdout = StringIO()\n",
    "                \n",
    "                try:\n",
    "                    # Train model\n",
    "                    model.train(processed_data, **params)\n",
    "                    \n",
    "                    # Generate synthetic data with error handling\n",
    "                    try:\n",
    "                        synthetic_data = model.generate(min(len(processed_data), 300))  # Limit for speed\n",
    "                    except Exception as gen_error:\n",
    "                        # If generation fails, return very low score\n",
    "                        return 0.001\n",
    "                    \n",
    "                    # Enhanced evaluation with better error handling\n",
    "                    X_real = processed_data.drop(columns=[TARGET_COLUMN])\n",
    "                    y_real = processed_data[TARGET_COLUMN]\n",
    "                    X_synth = synthetic_data.drop(columns=[TARGET_COLUMN])\n",
    "                    y_synth = synthetic_data[TARGET_COLUMN]\n",
    "                    \n",
    "                    # Ensure data compatibility\n",
    "                    if y_real.dtype != y_synth.dtype:\n",
    "                        if y_real.dtype in ['int32', 'int64'] and y_synth.dtype not in ['int32', 'int64']:\n",
    "                            y_synth = pd.to_numeric(y_synth, errors='coerce').round().astype(y_real.dtype)\n",
    "                    \n",
    "                    # Check for minimum class representation with better handling\n",
    "                    unique_real = y_real.nunique()\n",
    "                    unique_synth = y_synth.nunique()\n",
    "                    \n",
    "                    if unique_synth < 2 or unique_real < 2:\n",
    "                        return 0.001  # Very low score for insufficient diversity\n",
    "                    \n",
    "                    # Enhanced stratification handling\n",
    "                    def safe_stratify(y_data):\n",
    "                        \"\"\"Helper to determine if stratification is safe\"\"\"\n",
    "                        if y_data.nunique() <= 1:\n",
    "                            return None\n",
    "                        value_counts = y_data.value_counts()\n",
    "                        if value_counts.min() < 2:\n",
    "                            return None\n",
    "                        return y_data\n",
    "                    \n",
    "                    # Split data with enhanced stratification\n",
    "                    try:\n",
    "                        real_stratify = safe_stratify(y_real)\n",
    "                        synth_stratify = safe_stratify(y_synth)\n",
    "                        \n",
    "                        X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
    "                            X_real, y_real, test_size=0.3, random_state=42, stratify=real_stratify\n",
    "                        )\n",
    "                        X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(\n",
    "                            X_synth, y_synth, test_size=0.3, random_state=42, stratify=synth_stratify\n",
    "                        )\n",
    "                    except ValueError:\n",
    "                        # Fallback to simple split if stratification fails\n",
    "                        X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
    "                            X_real, y_real, test_size=0.3, random_state=42\n",
    "                        )\n",
    "                        X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(\n",
    "                            X_synth, y_synth, test_size=0.3, random_state=42\n",
    "                        )\n",
    "                    \n",
    "                    # TRTS evaluation with enhanced error handling\n",
    "                    clf = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "                    \n",
    "                    try:\n",
    "                        # TSTR: Train Synthetic, Test Real (primary utility metric)\n",
    "                        clf.fit(X_synth_train, y_synth_train)\n",
    "                        acc_tstr = clf.score(X_real_test, y_real_test)\n",
    "                        \n",
    "                        # TRTR: Train Real, Test Real (baseline)\n",
    "                        clf.fit(X_real_train, y_real_train)\n",
    "                        acc_trtr = clf.score(X_real_test, y_real_test)\n",
    "                        \n",
    "                        # Calculate utility score with bounds checking\n",
    "                        utility_score = acc_tstr / acc_trtr if acc_trtr > 0 else 0\n",
    "                        utility_score = np.clip(utility_score, 0, 2)  # Reasonable bounds\n",
    "                    except Exception as clf_error:\n",
    "                        utility_score = 0.001\n",
    "                    \n",
    "                    # Enhanced similarity score with multiple metrics\n",
    "                    similarity_scores = []\n",
    "                    for col in X_real.columns:\n",
    "                        if col in X_synth.columns:\n",
    "                            try:\n",
    "                                # Mean-based similarity\n",
    "                                mean_diff = abs(X_real[col].mean() - X_synth[col].mean())\n",
    "                                real_std = X_real[col].std()\n",
    "                                if real_std > 0:\n",
    "                                    mean_similarity = 1 / (1 + mean_diff / real_std)\n",
    "                                    similarity_scores.append(mean_similarity)\n",
    "                                \n",
    "                                # Std-based similarity  \n",
    "                                std_diff = abs(X_real[col].std() - X_synth[col].std())\n",
    "                                if real_std > 0:\n",
    "                                    std_similarity = 1 / (1 + std_diff / real_std)\n",
    "                                    similarity_scores.append(std_similarity)\n",
    "                                    \n",
    "                            except Exception:\n",
    "                                continue\n",
    "                    \n",
    "                    similarity_score = np.mean(similarity_scores) if similarity_scores else 0.5\n",
    "                    similarity_score = np.clip(similarity_score, 0, 1)  # Ensure bounds\n",
    "                    \n",
    "                    # Enhanced combined score (60% utility, 40% similarity)\n",
    "                    combined_score = 0.6 * utility_score + 0.4 * similarity_score\n",
    "                    combined_score = np.clip(combined_score, 0, 2)  # Reasonable bounds\n",
    "                    \n",
    "                    # Store metrics in trial\n",
    "                    trial.set_user_attr('utility_score', utility_score)\n",
    "                    trial.set_user_attr('similarity_score', similarity_score)\n",
    "                    trial.set_user_attr('acc_tstr', acc_tstr if 'acc_tstr' in locals() else 0)\n",
    "                    trial.set_user_attr('acc_trtr', acc_trtr if 'acc_trtr' in locals() else 0)\n",
    "                    \n",
    "                    return combined_score\n",
    "                    \n",
    "                finally:\n",
    "                    sys.stdout = old_stdout\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Only print failures occasionally to avoid spam\n",
    "                if trial_num % 20 == 0:\n",
    "                    print(f\"\\n   ‚ö†Ô∏è Trial {trial_num} failed: {str(e)[:50]}...\")\n",
    "                return 0.001  # Return very low score instead of 0.0\n",
    "        \n",
    "        return objective\n",
    "    \n",
    "    # Tune each successful model with enhanced hyperparameter spaces\n",
    "    for model_idx, model_name in enumerate(successful_models, 1):\n",
    "        print(f\"\\n[{model_idx}/{len(successful_models)}] üîß TUNING {model_name.upper()}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Get model class\n",
    "            if model_name == 'CTGAN':\n",
    "                model_class = CTGANModel\n",
    "            elif model_name == 'TVAE':\n",
    "                model_class = TVAEModel\n",
    "            elif model_name == 'CopulaGAN':\n",
    "                model_class = CopulaGANModel\n",
    "            elif model_name == 'GANerAid':\n",
    "                model_class = GANerAidModel\n",
    "            elif model_name == 'TableGAN':\n",
    "                model_class = TableGANModel\n",
    "            else:\n",
    "                print(f\"   ‚ùå Unknown model: {model_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Display enhanced hyperparameter space info\n",
    "            temp_model = model_class()\n",
    "            hyperparameter_space = temp_model.get_hyperparameter_space()\n",
    "            print(f\"üìä Enhanced hyperparameter space: {len(hyperparameter_space)} parameters\")\n",
    "            \n",
    "            # Show key parameters being optimized\n",
    "            key_params = list(hyperparameter_space.keys())[:5]  # Show first 5\n",
    "            print(f\"   Key parameters: {', '.join(key_params)}\")\n",
    "            if len(hyperparameter_space) > 5:\n",
    "                print(f\"   (+{len(hyperparameter_space) - 5} more parameters)\")\n",
    "            \n",
    "            # Create optimization study with suppressed output\n",
    "            if OPTUNA_AVAILABLE:\n",
    "                # Suppress Optuna logging\n",
    "                optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "                \n",
    "                study = optuna.create_study(\n",
    "                    direction='maximize',\n",
    "                    sampler=TPESampler(seed=42),\n",
    "                    study_name=f'{model_name}_enhanced_optimization_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "                )\n",
    "                \n",
    "                # Trial counter for progress tracking\n",
    "                current_trial = [0]\n",
    "                objective_func = create_objective_function(model_name, model_class, current_trial)\n",
    "                \n",
    "                print(f\"üöÄ Optimizing with enhanced hyperparameter space...\")\n",
    "                study.optimize(objective_func, n_trials=N_TRIALS)\n",
    "                print()  # New line after dots\n",
    "                \n",
    "                # Extract results\n",
    "                best_trial = study.best_trial\n",
    "                best_params = best_trial.params.copy()\n",
    "                best_score = best_trial.value\n",
    "                \n",
    "                # Ensure epochs is properly set for final training\n",
    "                if 'epochs' not in best_params:\n",
    "                    best_params['epochs'] = TUNE_EPOCHS\n",
    "                \n",
    "                phase2_best_params[model_name] = best_params\n",
    "                phase2_best_scores[model_name] = best_score\n",
    "                \n",
    "                # Store detailed results with enhanced metrics\n",
    "                phase2_results[model_name] = {\n",
    "                    'status': 'success',\n",
    "                    'best_score': best_score,\n",
    "                    'best_params': best_params,\n",
    "                    'trials_completed': len(study.trials),\n",
    "                    'utility_score': best_trial.user_attrs.get('utility_score', 0),\n",
    "                    'similarity_score': best_trial.user_attrs.get('similarity_score', 0),\n",
    "                    'acc_tstr': best_trial.user_attrs.get('acc_tstr', 0),\n",
    "                    'acc_trtr': best_trial.user_attrs.get('acc_trtr', 0),\n",
    "                    'hyperparameter_count': len(hyperparameter_space),\n",
    "                    'optimization_method': 'TPE Bayesian'\n",
    "                }\n",
    "                \n",
    "                print(f\"‚úÖ Enhanced optimization complete!\")\n",
    "                print(f\"üèÜ Best score: {best_score:.4f}\")\n",
    "                print(f\"   ‚Ä¢ Utility: {best_trial.user_attrs.get('utility_score', 0):.3f}\")\n",
    "                print(f\"   ‚Ä¢ Similarity: {best_trial.user_attrs.get('similarity_score', 0):.3f}\")\n",
    "                print(f\"   ‚Ä¢ Hyperparameters optimized: {len(hyperparameter_space)}\")\n",
    "                \n",
    "                # Show top 3 most important parameters (by name for consistency)\n",
    "                important_params = sorted(best_params.items())[:3]\n",
    "                print(f\"   ‚Ä¢ Key optimized params: {', '.join([f'{k}={v:.3g}' if isinstance(v, float) else f'{k}={v}' for k, v in important_params])}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Optuna not available - using default parameters\")\n",
    "                phase2_best_params[model_name] = phase1_results[model_name]['parameters']\n",
    "                phase2_best_scores[model_name] = 0.75  # Default score\n",
    "                phase2_results[model_name] = {\n",
    "                    'status': 'default',\n",
    "                    'best_score': 0.75,\n",
    "                    'best_params': phase1_results[model_name]['parameters'],\n",
    "                    'hyperparameter_count': len(hyperparameter_space),\n",
    "                    'optimization_method': 'Default'\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"   ‚ùå {model_name} enhanced hypertuning failed: {error_msg[:80]}...\")\n",
    "            phase2_results[model_name] = {\n",
    "                'status': 'failed',\n",
    "                'error': error_msg,\n",
    "                'hyperparameter_count': 0,\n",
    "                'optimization_method': 'Failed'\n",
    "            }\n",
    "    \n",
    "    # Enhanced Phase 2 Summary\n",
    "    print(f\"\\nüìä ENHANCED PHASE 2 SUMMARY\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    tuned_models = [name for name, result in phase2_results.items() \n",
    "                   if result['status'] in ['success', 'default']]\n",
    "    failed_tuning = [name for name, result in phase2_results.items() \n",
    "                    if result['status'] == 'failed']\n",
    "    \n",
    "    print(f\"‚úÖ Successfully tuned: {len(tuned_models)}/{len(successful_models)} models\")\n",
    "    if tuned_models:\n",
    "        print(f\"   Models: {', '.join(tuned_models)}\")\n",
    "    if failed_tuning:\n",
    "        print(f\"‚ùå Failed tuning: {len(failed_tuning)} models ({', '.join(failed_tuning)})\")\n",
    "    \n",
    "    if tuned_models:\n",
    "        print(f\"\\nüèÜ Enhanced Optimization Results:\")\n",
    "        sorted_models = sorted(tuned_models, key=lambda x: phase2_best_scores[x], reverse=True)\n",
    "        for model_name in sorted_models:\n",
    "            result = phase2_results[model_name]\n",
    "            score = phase2_best_scores[model_name]\n",
    "            param_count = result.get('hyperparameter_count', 0)\n",
    "            method = result.get('optimization_method', 'Unknown')\n",
    "            print(f\"   ‚Ä¢ {model_name:>10}: {score:.4f} ({param_count} params, {method})\")\n",
    "        \n",
    "        print(f\"\\nüìä Hyperparameter Space Summary:\")\n",
    "        total_params = sum(phase2_results[model]['hyperparameter_count'] for model in tuned_models if 'hyperparameter_count' in phase2_results[model])\n",
    "        avg_params = total_params / len(tuned_models) if tuned_models else 0\n",
    "        print(f\"   ‚Ä¢ Total parameters across all models: {total_params}\")\n",
    "        print(f\"   ‚Ä¢ Average parameters per model: {avg_params:.1f}\")\n",
    "        print(f\"   ‚Ä¢ Total optimization trials: {N_TRIALS * len(tuned_models)}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Enhanced Phase 2 completed. Best model: {sorted_models[0]} with {phase2_results[sorted_models[0]].get('hyperparameter_count', 0)} optimized parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Re-train Best Models with Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ PHASE 3: RE-TRAIN BEST MODELS WITH OPTIMAL PARAMETERS\n",
      "============================================================\n",
      "üìä Final Training Configuration:\n",
      "   ‚Ä¢ Training epochs: 200\n",
      "   ‚Ä¢ Models to re-train: 5\n",
      "   ‚Ä¢ Using optimal hyperparameters from Phase 2\n",
      "\n",
      "üèÜ FINAL TRAINING: CTGAN\n",
      "-----------------------------------\n",
      "   üîß Optimal parameters:\n",
      "      ‚Ä¢ epochs: 200\n",
      "      ‚Ä¢ batch_size: 256\n",
      "      ‚Ä¢ generator_lr: 5.69e-04\n",
      "      ‚Ä¢ discriminator_lr: 6.68e-05\n",
      "      ‚Ä¢ generator_dim: (256, 256)\n",
      "      ‚Ä¢ discriminator_dim: (512, 512)\n",
      "      ‚Ä¢ pac: 6\n",
      "      ‚Ä¢ discriminator_steps: 3\n",
      "      ‚Ä¢ generator_decay: 3.32e-07\n",
      "      ‚Ä¢ discriminator_decay: 8.96e-06\n",
      "   üöÄ Training with optimal parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (-0.87) | Discrim. (0.12): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 28.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Training completed in 16.35 seconds\n",
      "   üé≤ Generating final synthetic data...\n",
      "   ‚úÖ Generation completed in 0.029 seconds\n",
      "   üìä Generated data shape: (569, 6)\n",
      "   ‚úÖ CTGAN final training completed successfully\n",
      "   üíæ Synthetic data exported: ctgan_final_synthetic_data.csv\n",
      "\n",
      "üèÜ FINAL TRAINING: TVAE\n",
      "-----------------------------------\n",
      "   üîß Optimal parameters:\n",
      "      ‚Ä¢ epochs: 200\n",
      "      ‚Ä¢ compress_dims: (64, 128, 64)\n",
      "      ‚Ä¢ decompress_dims: (256, 128)\n",
      "      ‚Ä¢ l2scale: 2.34e-04\n",
      "      ‚Ä¢ batch_size: 64\n",
      "      ‚Ä¢ loss_factor: 7\n",
      "      ‚Ä¢ enforce_min_max_values: True\n",
      "      ‚Ä¢ enforce_rounding: True\n",
      "      ‚Ä¢ learning_rate: 1.57e-04\n",
      "      ‚Ä¢ beta: 1.9431035109496402\n",
      "      ‚Ä¢ latent_dim: 288\n",
      "      ‚Ä¢ dropout_rate: 0.2815461270246629\n",
      "   üöÄ Training with optimal parameters...\n",
      "   ‚úÖ Training completed in 8.50 seconds\n",
      "   üé≤ Generating final synthetic data...\n",
      "   ‚úÖ Generation completed in 0.044 seconds\n",
      "   üìä Generated data shape: (569, 6)\n",
      "   ‚úÖ TVAE final training completed successfully\n",
      "   üíæ Synthetic data exported: tvae_final_synthetic_data.csv\n",
      "\n",
      "üèÜ FINAL TRAINING: COPULAGAN\n",
      "-----------------------------------\n",
      "   üîß Optimal parameters:\n",
      "      ‚Ä¢ epochs: 200\n",
      "      ‚Ä¢ batch_size: 2000\n",
      "      ‚Ä¢ generator_lr: 1.03e-03\n",
      "      ‚Ä¢ discriminator_lr: 4.62e-05\n",
      "      ‚Ä¢ generator_dim: (512, 256)\n",
      "      ‚Ä¢ discriminator_dim: (512, 1024, 512)\n",
      "      ‚Ä¢ pac: 20\n",
      "      ‚Ä¢ generator_decay: 4.22e-07\n",
      "      ‚Ä¢ discriminator_decay: 1.29e-06\n",
      "      ‚Ä¢ discriminator_steps: 2\n",
      "      ‚Ä¢ beta1: 0.5967860946937058\n",
      "      ‚Ä¢ beta2: 0.9981024311937617\n",
      "      ‚Ä¢ copula_regularization: 5.88e-03\n",
      "      ‚Ä¢ gradient_penalty: 9.960165317474356\n",
      "   üöÄ Training with optimal parameters...\n",
      "   ‚úÖ Training completed in 23.83 seconds\n",
      "   üé≤ Generating final synthetic data...\n",
      "   ‚úÖ Generation completed in 0.077 seconds\n",
      "   üìä Generated data shape: (569, 6)\n",
      "   ‚úÖ CopulaGAN final training completed successfully\n",
      "   üíæ Synthetic data exported: copulagan_final_synthetic_data.csv\n",
      "\n",
      "üèÜ FINAL TRAINING: GANERAID\n",
      "-----------------------------------\n",
      "   üîß Optimal parameters:\n",
      "      ‚Ä¢ epochs: 200\n",
      "      ‚Ä¢ lr_d: 7.61e-05\n",
      "      ‚Ä¢ lr_g: 2.28e-03\n",
      "      ‚Ä¢ hidden_feature_space: 200\n",
      "      ‚Ä¢ batch_size: 16\n",
      "      ‚Ä¢ nr_of_rows: 20\n",
      "      ‚Ä¢ binary_noise: 0.5234018207909888\n",
      "      ‚Ä¢ generator_dropout: 3.48e-03\n",
      "      ‚Ä¢ discriminator_dropout: 0.25537365128878287\n",
      "      ‚Ä¢ weight_decay: 1.22e-06\n",
      "      ‚Ä¢ beta1: 0.2776862483765842\n",
      "      ‚Ä¢ beta2: 0.9118666713660346\n",
      "      ‚Ä¢ gradient_penalty_weight: 3.3761517140362796\n",
      "      ‚Ä¢ privacy_epsilon: 7.688106801474955\n",
      "      ‚Ä¢ feature_noise_std: 0.10372885028601901\n",
      "   üöÄ Training with optimal parameters...\n",
      "Initialized gan with the following parameters: \n",
      "lr_d = 0.0005\n",
      "lr_g = 0.0005\n",
      "hidden_feature_space = 200\n",
      "batch_size = 100\n",
      "nr_of_rows = 25\n",
      "binary_noise = 0.2\n",
      "Start training of gan for 200 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.06it/s, loss=d error: 0.5319346785545349 --- g error 2.6366875171661377] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Training completed in 7.71 seconds\n",
      "   üé≤ Generating final synthetic data...\n",
      "Generating 569 samples\n",
      "   ‚úÖ Generation completed in 0.140 seconds\n",
      "   üìä Generated data shape: (569, 6)\n",
      "   ‚úÖ GANerAid final training completed successfully\n",
      "   üíæ Synthetic data exported: ganeraid_final_synthetic_data.csv\n",
      "\n",
      "üèÜ FINAL TRAINING: TABLEGAN\n",
      "-----------------------------------\n",
      "   üîß Optimal parameters:\n",
      "      ‚Ä¢ epochs: 200\n",
      "      ‚Ä¢ batch_size: 256\n",
      "      ‚Ä¢ learning_rate: 4.05e-04\n",
      "      ‚Ä¢ noise_dim: 128\n",
      "      ‚Ä¢ generator_dims: [512, 1024, 512]\n",
      "      ‚Ä¢ discriminator_dims: [512, 256, 128]\n",
      "      ‚Ä¢ generator_dropout: 0.3775971996178893\n",
      "      ‚Ä¢ discriminator_dropout: 0.45059834160751555\n",
      "      ‚Ä¢ discriminator_updates: 5\n",
      "      ‚Ä¢ beta1: 0.4338522413982129\n",
      "      ‚Ä¢ beta2: 0.9325876839254781\n",
      "      ‚Ä¢ label_smoothing: 0.1271296352218435\n",
      "      ‚Ä¢ gradient_penalty: 33.79782735170353\n",
      "   üöÄ Training with optimal parameters...\n",
      "   ‚úÖ Training completed in 7.40 seconds\n",
      "   üé≤ Generating final synthetic data...\n",
      "   ‚úÖ Generation completed in 0.005 seconds\n",
      "   üìä Generated data shape: (569, 6)\n",
      "   ‚úÖ TableGAN final training completed successfully\n",
      "   üíæ Synthetic data exported: tablegan_final_synthetic_data.csv\n",
      "\n",
      "üìä PHASE 3 SUMMARY\n",
      "=========================\n",
      "‚úÖ Successfully trained: 5 (CTGAN, TVAE, CopulaGAN, GANerAid, TableGAN)\n",
      "\n",
      "‚è±Ô∏è Final Training Performance:\n",
      "   ‚Ä¢ CTGAN: 16.3s training, 0.029s generation\n",
      "   ‚Ä¢ TVAE: 8.5s training, 0.044s generation\n",
      "   ‚Ä¢ CopulaGAN: 23.8s training, 0.077s generation\n",
      "   ‚Ä¢ GANerAid: 7.7s training, 0.140s generation\n",
      "   ‚Ä¢ TableGAN: 7.4s training, 0.005s generation\n",
      "\n",
      "üéØ Phase 3 completed. Ready for comprehensive evaluation.\n",
      "\n",
      "üíæ Phase 3 summary exported: phase3_final_models_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Re-train best models with optimal parameters\n",
    "print(\"üèÜ PHASE 3: RE-TRAIN BEST MODELS WITH OPTIMAL PARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not tuned_models:\n",
    "    print(\"‚ö†Ô∏è No tuned models from Phase 2. Cannot proceed with final training.\")\n",
    "else:\n",
    "    # Initialize results storage\n",
    "    phase3_results = {}\n",
    "    phase3_models = {}\n",
    "    phase3_synthetic_data = {}\n",
    "    \n",
    "    # Final training configuration\n",
    "    FINAL_EPOCHS = 200  # Increased for final models\n",
    "    \n",
    "    print(f\"üìä Final Training Configuration:\")\n",
    "    print(f\"   ‚Ä¢ Training epochs: {FINAL_EPOCHS:,}\")\n",
    "    print(f\"   ‚Ä¢ Models to re-train: {len(tuned_models)}\")\n",
    "    print(f\"   ‚Ä¢ Using optimal hyperparameters from Phase 2\")\n",
    "    \n",
    "    # Re-train each tuned model with optimal parameters\n",
    "    for model_name in tuned_models:\n",
    "        print(f\"\\nüèÜ FINAL TRAINING: {model_name.upper()}\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        try:\n",
    "            # Get optimal parameters\n",
    "            optimal_params = phase2_best_params[model_name].copy()\n",
    "            optimal_params['epochs'] = FINAL_EPOCHS  # Use final epochs\n",
    "            \n",
    "            print(f\"   üîß Optimal parameters:\")\n",
    "            for param, value in optimal_params.items():\n",
    "                if isinstance(value, float) and value < 0.01:\n",
    "                    print(f\"      ‚Ä¢ {param}: {value:.2e}\")\n",
    "                else:\n",
    "                    print(f\"      ‚Ä¢ {param}: {value}\")\n",
    "            \n",
    "            # Initialize model\n",
    "            if model_name == 'CTGAN':\n",
    "                model = CTGANModel()\n",
    "            elif model_name == 'TVAE':\n",
    "                model = TVAEModel()\n",
    "            elif model_name == 'CopulaGAN':\n",
    "                model = CopulaGANModel()\n",
    "            elif model_name == 'GANerAid':\n",
    "                model = GANerAidModel()\n",
    "            elif model_name == 'TableGAN':\n",
    "                model = TableGANModel()\n",
    "            \n",
    "            # Train with optimal parameters\n",
    "            print(f\"   üöÄ Training with optimal parameters...\")\n",
    "            training_start = time.time()\n",
    "            \n",
    "            model.train(processed_data, **optimal_params)\n",
    "            \n",
    "            training_end = time.time()\n",
    "            training_time = training_end - training_start\n",
    "            \n",
    "            print(f\"   ‚úÖ Training completed in {training_time:.2f} seconds\")\n",
    "            \n",
    "            # Generate synthetic data\n",
    "            print(f\"   üé≤ Generating final synthetic data...\")\n",
    "            generation_start = time.time()\n",
    "            \n",
    "            synthetic_data = model.generate(len(processed_data))\n",
    "            \n",
    "            generation_end = time.time()\n",
    "            generation_time = generation_end - generation_start\n",
    "            \n",
    "            print(f\"   ‚úÖ Generation completed in {generation_time:.3f} seconds\")\n",
    "            print(f\"   üìä Generated data shape: {synthetic_data.shape}\")\n",
    "            \n",
    "            # Store results\n",
    "            phase3_models[model_name] = model\n",
    "            phase3_synthetic_data[model_name] = synthetic_data\n",
    "            \n",
    "            phase3_results[model_name] = {\n",
    "                'status': 'success',\n",
    "                'training_time': training_time,\n",
    "                'generation_time': generation_time,\n",
    "                'generated_samples': len(synthetic_data),\n",
    "                'optimal_params': optimal_params,\n",
    "                'tuning_score': phase2_best_scores[model_name]\n",
    "            }\n",
    "            \n",
    "            print(f\"   ‚úÖ {model_name} final training completed successfully\")\n",
    "            \n",
    "            # Export synthetic data\n",
    "            if EXPORT_TABLES:\n",
    "                synthetic_data.to_csv(RESULTS_DIR / f'{model_name.lower()}_final_synthetic_data.csv', index=False)\n",
    "                print(f\"   üíæ Synthetic data exported: {model_name.lower()}_final_synthetic_data.csv\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"   ‚ùå {model_name} final training failed: {error_msg[:100]}...\")\n",
    "            phase3_results[model_name] = {\n",
    "                'status': 'failed',\n",
    "                'error': error_msg\n",
    "            }\n",
    "    \n",
    "    # Phase 3 Summary\n",
    "    print(f\"\\nüìä PHASE 3 SUMMARY\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    final_models = [name for name, result in phase3_results.items() if result['status'] == 'success']\n",
    "    failed_final = [name for name, result in phase3_results.items() if result['status'] == 'failed']\n",
    "    \n",
    "    print(f\"‚úÖ Successfully trained: {len(final_models)} ({', '.join(final_models)})\")\n",
    "    if failed_final:\n",
    "        print(f\"‚ùå Failed final training: {len(failed_final)} ({', '.join(failed_final)})\")\n",
    "    \n",
    "    if final_models:\n",
    "        print(f\"\\n‚è±Ô∏è Final Training Performance:\")\n",
    "        for model_name in final_models:\n",
    "            result = phase3_results[model_name]\n",
    "            print(f\"   ‚Ä¢ {model_name}: {result['training_time']:.1f}s training, {result['generation_time']:.3f}s generation\")\n",
    "        \n",
    "        print(f\"\\nüéØ Phase 3 completed. Ready for comprehensive evaluation.\")\n",
    "        \n",
    "        # Export final results summary\n",
    "        if EXPORT_TABLES:\n",
    "            final_summary = []\n",
    "            for model_name in final_models:\n",
    "                result = phase3_results[model_name]\n",
    "                final_summary.append({\n",
    "                    'Model': model_name,\n",
    "                    'Tuning_Score': result['tuning_score'],\n",
    "                    'Training_Time': result['training_time'],\n",
    "                    'Generation_Time': result['generation_time'],\n",
    "                    'Generated_Samples': result['generated_samples']\n",
    "                })\n",
    "            \n",
    "            summary_df = pd.DataFrame(final_summary)\n",
    "            summary_df.to_csv(RESULTS_DIR / 'phase3_final_models_summary.csv', index=False)\n",
    "            print(f\"\\nüíæ Phase 3 summary exported: phase3_final_models_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Comprehensive Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä PHASE 4: COMPREHENSIVE MODEL EVALUATION AND COMPARISON\n",
      "=================================================================\n",
      "üìä Evaluation Configuration:\n",
      "   ‚Ä¢ Models to evaluate: 5\n",
      "   ‚Ä¢ Evaluation frameworks: TRTS + Statistical Similarity\n",
      "   ‚Ä¢ Baseline: Original data performance\n",
      "\n",
      "üìä EVALUATING CTGAN\n",
      "------------------------------\n",
      "   üéØ TRTS Framework Evaluation...\n",
      "      ‚úÖ TRTS completed - Utility: 0.7806, Quality: 0.6941\n",
      "   üìä Statistical Similarity Analysis...\n",
      "      ‚úÖ Similarity completed - Ratio: 0.0000\n",
      "   üèÜ Computing combined evaluation score...\n",
      "      ‚úÖ Combined score: 0.5205\n",
      "      üìä Breakdown - Utility: 0.7806, Quality: 0.6941, Similarity: 0.0000\n",
      "\n",
      "üìä EVALUATING TVAE\n",
      "------------------------------\n",
      "   üéØ TRTS Framework Evaluation...\n",
      "      ‚úÖ TRTS completed - Utility: 0.9674, Quality: 0.9808\n",
      "   üìä Statistical Similarity Analysis...\n",
      "      ‚úÖ Similarity completed - Ratio: 0.0000\n",
      "   üèÜ Computing combined evaluation score...\n",
      "      ‚úÖ Combined score: 0.6812\n",
      "      üìä Breakdown - Utility: 0.9674, Quality: 0.9808, Similarity: 0.0000\n",
      "\n",
      "üìä EVALUATING COPULAGAN\n",
      "------------------------------\n",
      "   üéØ TRTS Framework Evaluation...\n",
      "      ‚úÖ TRTS completed - Utility: 0.4836, Quality: 0.5773\n",
      "   üìä Statistical Similarity Analysis...\n",
      "      ‚úÖ Similarity completed - Ratio: 0.2000\n",
      "   üèÜ Computing combined evaluation score...\n",
      "      ‚úÖ Combined score: 0.4267\n",
      "      üìä Breakdown - Utility: 0.4836, Quality: 0.5773, Similarity: 0.2000\n",
      "\n",
      "üìä EVALUATING GANERAID\n",
      "------------------------------\n",
      "   üéØ TRTS Framework Evaluation...\n",
      "      ‚úÖ TRTS completed - Utility: 0.6977, Quality: 0.6731\n",
      "   üìä Statistical Similarity Analysis...\n",
      "      ‚úÖ Similarity completed - Ratio: 0.0000\n",
      "   üèÜ Computing combined evaluation score...\n",
      "      ‚úÖ Combined score: 0.4810\n",
      "      üìä Breakdown - Utility: 0.6977, Quality: 0.6731, Similarity: 0.0000\n",
      "\n",
      "üìä EVALUATING TABLEGAN\n",
      "------------------------------\n",
      "   üéØ TRTS Framework Evaluation...\n",
      "   ‚ùå TableGAN evaluation failed: The least populated class in y has only 1 member, which is too few. The minimum number of groups for...\n",
      "\n",
      "üèÜ PHASE 4 SUMMARY - MODEL RANKING\n",
      "=============================================\n",
      "ü•á MODEL RANKING (by combined score):\n",
      "   1. TVAE: 0.6812\n",
      "      ‚Ä¢ Utility: 0.9674\n",
      "      ‚Ä¢ Quality: 0.9808\n",
      "      ‚Ä¢ Similarity: 0.0000\n",
      "   2. CTGAN: 0.5205\n",
      "      ‚Ä¢ Utility: 0.7806\n",
      "      ‚Ä¢ Quality: 0.6941\n",
      "      ‚Ä¢ Similarity: 0.0000\n",
      "   3. GANerAid: 0.4810\n",
      "      ‚Ä¢ Utility: 0.6977\n",
      "      ‚Ä¢ Quality: 0.6731\n",
      "      ‚Ä¢ Similarity: 0.0000\n",
      "   4. CopulaGAN: 0.4267\n",
      "      ‚Ä¢ Utility: 0.4836\n",
      "      ‚Ä¢ Quality: 0.5773\n",
      "      ‚Ä¢ Similarity: 0.2000\n",
      "\n",
      "üèÜ BEST OVERALL MODEL: TVAE\n",
      "üìä Combined Score: 0.6812\n",
      "\n",
      "üíæ Model ranking exported: final_model_ranking.csv\n",
      "üíæ TRTS results exported: detailed_trts_results.csv\n",
      "\n",
      "üéØ Phase 4 completed. Best model identified: TVAE\n"
     ]
    }
   ],
   "source": [
    "# Phase 4: Comprehensive evaluation and comparison\n",
    "print(\"üìä PHASE 4: COMPREHENSIVE MODEL EVALUATION AND COMPARISON\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "if not final_models:\n",
    "    print(\"‚ö†Ô∏è No final models from Phase 3. Cannot proceed with evaluation.\")\n",
    "else:\n",
    "    # Initialize evaluation results storage\n",
    "    evaluation_results = {}\n",
    "    trts_results = {}\n",
    "    similarity_results = {}\n",
    "    \n",
    "    print(f\"üìä Evaluation Configuration:\")\n",
    "    print(f\"   ‚Ä¢ Models to evaluate: {len(final_models)}\")\n",
    "    print(f\"   ‚Ä¢ Evaluation frameworks: TRTS + Statistical Similarity\")\n",
    "    print(f\"   ‚Ä¢ Baseline: Original data performance\")\n",
    "    \n",
    "    # Comprehensive evaluation for each final model\n",
    "    for model_name in final_models:\n",
    "        print(f\"\\nüìä EVALUATING {model_name.upper()}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        try:\n",
    "            synthetic_data = phase3_synthetic_data[model_name]\n",
    "            \n",
    "            # 1. TRTS Framework Evaluation\n",
    "            print(f\"   üéØ TRTS Framework Evaluation...\")\n",
    "            \n",
    "            X_real = processed_data.drop(columns=[TARGET_COLUMN])\n",
    "            y_real = processed_data[TARGET_COLUMN]\n",
    "            X_synth = synthetic_data.drop(columns=[TARGET_COLUMN])\n",
    "            y_synth = synthetic_data[TARGET_COLUMN]\n",
    "            \n",
    "            # Split data\n",
    "            X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
    "                X_real, y_real, test_size=0.3, random_state=42,\n",
    "                stratify=y_real if y_real.nunique() > 1 else None\n",
    "            )\n",
    "            X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(\n",
    "                X_synth, y_synth, test_size=0.3, random_state=42,\n",
    "                stratify=y_synth if y_synth.nunique() > 1 else None\n",
    "            )\n",
    "            \n",
    "            # Initialize classifiers\n",
    "            dt_clf = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "            rf_clf = RandomForestClassifier(random_state=42, n_estimators=50)\n",
    "            \n",
    "            # TRTS scenarios with multiple classifiers\n",
    "            trts_scores = {}\n",
    "            \n",
    "            for clf_name, clf in [('DecisionTree', dt_clf), ('RandomForest', rf_clf)]:\n",
    "                # TRTR: Train Real, Test Real (baseline)\n",
    "                clf.fit(X_real_train, y_real_train)\n",
    "                acc_trtr = clf.score(X_real_test, y_real_test)\n",
    "                \n",
    "                # TSTS: Train Synthetic, Test Synthetic\n",
    "                clf.fit(X_synth_train, y_synth_train)\n",
    "                acc_tsts = clf.score(X_synth_test, y_synth_test)\n",
    "                \n",
    "                # TRTS: Train Real, Test Synthetic\n",
    "                clf.fit(X_real_train, y_real_train)\n",
    "                acc_trts = clf.score(X_synth_test, y_synth_test)\n",
    "                \n",
    "                # TSTR: Train Synthetic, Test Real\n",
    "                clf.fit(X_synth_train, y_synth_train)\n",
    "                acc_tstr = clf.score(X_real_test, y_real_test)\n",
    "                \n",
    "                trts_scores[clf_name] = {\n",
    "                    'TRTR': acc_trtr,\n",
    "                    'TSTS': acc_tsts,\n",
    "                    'TRTS': acc_trts,\n",
    "                    'TSTR': acc_tstr,\n",
    "                    'Utility': acc_tstr / acc_trtr if acc_trtr > 0 else 0,\n",
    "                    'Quality': acc_trts / acc_trtr if acc_trtr > 0 else 0\n",
    "                }\n",
    "            \n",
    "            # Average TRTS scores\n",
    "            avg_trts = {}\n",
    "            for metric in ['TRTR', 'TSTS', 'TRTS', 'TSTR', 'Utility', 'Quality']:\n",
    "                avg_trts[metric] = np.mean([trts_scores[clf][metric] for clf in trts_scores.keys()])\n",
    "            \n",
    "            trts_results[model_name] = {\n",
    "                'individual': trts_scores,\n",
    "                'average': avg_trts\n",
    "            }\n",
    "            \n",
    "            print(f\"      ‚úÖ TRTS completed - Utility: {avg_trts['Utility']:.4f}, Quality: {avg_trts['Quality']:.4f}\")\n",
    "            \n",
    "            # 2. Statistical Similarity Analysis\n",
    "            print(f\"   üìä Statistical Similarity Analysis...\")\n",
    "            \n",
    "            similarity_metrics = {}\n",
    "            \n",
    "            # Feature-wise similarity\n",
    "            feature_similarities = []\n",
    "            for col in X_real.columns:\n",
    "                if col in X_synth.columns:\n",
    "                    # Kolmogorov-Smirnov test\n",
    "                    ks_stat, ks_pval = stats.ks_2samp(X_real[col], X_synth[col])\n",
    "                    \n",
    "                    # Mean and std differences\n",
    "                    mean_diff = abs(X_real[col].mean() - X_synth[col].mean())\n",
    "                    std_diff = abs(X_real[col].std() - X_synth[col].std())\n",
    "                    \n",
    "                    # Normalized differences\n",
    "                    mean_norm_diff = mean_diff / X_real[col].std() if X_real[col].std() > 0 else 0\n",
    "                    std_norm_diff = std_diff / X_real[col].std() if X_real[col].std() > 0 else 0\n",
    "                    \n",
    "                    feature_similarities.append({\n",
    "                        'feature': col,\n",
    "                        'ks_statistic': ks_stat,\n",
    "                        'ks_pvalue': ks_pval,\n",
    "                        'mean_diff': mean_diff,\n",
    "                        'std_diff': std_diff,\n",
    "                        'mean_norm_diff': mean_norm_diff,\n",
    "                        'std_norm_diff': std_norm_diff,\n",
    "                        'similar': ks_pval > 0.05\n",
    "                    })\n",
    "            \n",
    "            # Aggregate similarity metrics\n",
    "            similarity_metrics = {\n",
    "                'avg_ks_statistic': np.mean([f['ks_statistic'] for f in feature_similarities]),\n",
    "                'avg_ks_pvalue': np.mean([f['ks_pvalue'] for f in feature_similarities]),\n",
    "                'similar_features': sum([f['similar'] for f in feature_similarities]),\n",
    "                'total_features': len(feature_similarities),\n",
    "                'similarity_ratio': sum([f['similar'] for f in feature_similarities]) / len(feature_similarities),\n",
    "                'avg_mean_norm_diff': np.mean([f['mean_norm_diff'] for f in feature_similarities]),\n",
    "                'avg_std_norm_diff': np.mean([f['std_norm_diff'] for f in feature_similarities])\n",
    "            }\n",
    "            \n",
    "            # Correlation similarity\n",
    "            real_corr = X_real.corr()\n",
    "            synth_corr = X_synth.corr()\n",
    "            corr_diff = np.abs(real_corr - synth_corr)\n",
    "            \n",
    "            # Get upper triangle (excluding diagonal)\n",
    "            mask = np.triu(np.ones_like(corr_diff, dtype=bool), k=1)\n",
    "            corr_diffs = corr_diff.values[mask]\n",
    "            \n",
    "            similarity_metrics['avg_corr_diff'] = np.mean(corr_diffs)\n",
    "            similarity_metrics['max_corr_diff'] = np.max(corr_diffs)\n",
    "            \n",
    "            similarity_results[model_name] = {\n",
    "                'feature_level': feature_similarities,\n",
    "                'aggregate': similarity_metrics\n",
    "            }\n",
    "            \n",
    "            print(f\"      ‚úÖ Similarity completed - Ratio: {similarity_metrics['similarity_ratio']:.4f}\")\n",
    "            \n",
    "            # 3. Combined Evaluation Score\n",
    "            print(f\"   üèÜ Computing combined evaluation score...\")\n",
    "            \n",
    "            # Weighted combination: 40% Utility + 30% Quality + 30% Similarity\n",
    "            combined_score = (\n",
    "                0.4 * avg_trts['Utility'] +\n",
    "                0.3 * avg_trts['Quality'] +\n",
    "                0.3 * similarity_metrics['similarity_ratio']\n",
    "            )\n",
    "            \n",
    "            evaluation_results[model_name] = {\n",
    "                'combined_score': combined_score,\n",
    "                'utility_score': avg_trts['Utility'],\n",
    "                'quality_score': avg_trts['Quality'],\n",
    "                'similarity_score': similarity_metrics['similarity_ratio'],\n",
    "                'trts_details': avg_trts,\n",
    "                'similarity_details': similarity_metrics\n",
    "            }\n",
    "            \n",
    "            print(f\"      ‚úÖ Combined score: {combined_score:.4f}\")\n",
    "            print(f\"      üìä Breakdown - Utility: {avg_trts['Utility']:.4f}, Quality: {avg_trts['Quality']:.4f}, Similarity: {similarity_metrics['similarity_ratio']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"   ‚ùå {model_name} evaluation failed: {error_msg[:100]}...\")\n",
    "            evaluation_results[model_name] = {\n",
    "                'combined_score': 0.0,\n",
    "                'error': error_msg\n",
    "            }\n",
    "    \n",
    "    # Phase 4 Summary - Ranking and Best Model Identification\n",
    "    print(f\"\\nüèÜ PHASE 4 SUMMARY - MODEL RANKING\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Sort models by combined score\n",
    "    evaluated_models = [name for name in evaluation_results.keys() \n",
    "                       if 'error' not in evaluation_results[name]]\n",
    "    \n",
    "    if evaluated_models:\n",
    "        sorted_models = sorted(evaluated_models, \n",
    "                              key=lambda x: evaluation_results[x]['combined_score'], \n",
    "                              reverse=True)\n",
    "        \n",
    "        print(f\"ü•á MODEL RANKING (by combined score):\")\n",
    "        for i, model_name in enumerate(sorted_models, 1):\n",
    "            result = evaluation_results[model_name]\n",
    "            print(f\"   {i}. {model_name}: {result['combined_score']:.4f}\")\n",
    "            print(f\"      ‚Ä¢ Utility: {result['utility_score']:.4f}\")\n",
    "            print(f\"      ‚Ä¢ Quality: {result['quality_score']:.4f}\")\n",
    "            print(f\"      ‚Ä¢ Similarity: {result['similarity_score']:.4f}\")\n",
    "        \n",
    "        best_model = sorted_models[0]\n",
    "        print(f\"\\nüèÜ BEST OVERALL MODEL: {best_model}\")\n",
    "        print(f\"üìä Combined Score: {evaluation_results[best_model]['combined_score']:.4f}\")\n",
    "        \n",
    "        # Export evaluation results\n",
    "        if EXPORT_TABLES:\n",
    "            # Model ranking table\n",
    "            ranking_data = []\n",
    "            for i, model_name in enumerate(sorted_models, 1):\n",
    "                result = evaluation_results[model_name]\n",
    "                ranking_data.append({\n",
    "                    'Rank': i,\n",
    "                    'Model': model_name,\n",
    "                    'Combined_Score': result['combined_score'],\n",
    "                    'Utility_Score': result['utility_score'],\n",
    "                    'Quality_Score': result['quality_score'],\n",
    "                    'Similarity_Score': result['similarity_score']\n",
    "                })\n",
    "            \n",
    "            ranking_df = pd.DataFrame(ranking_data)\n",
    "            ranking_df.to_csv(RESULTS_DIR / 'final_model_ranking.csv', index=False)\n",
    "            print(f\"\\nüíæ Model ranking exported: final_model_ranking.csv\")\n",
    "            \n",
    "            # Detailed TRTS results\n",
    "            trts_data = []\n",
    "            for model_name in evaluated_models:\n",
    "                avg_trts = trts_results[model_name]['average']\n",
    "                trts_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'TRTR': avg_trts['TRTR'],\n",
    "                    'TSTS': avg_trts['TSTS'],\n",
    "                    'TRTS': avg_trts['TRTS'],\n",
    "                    'TSTR': avg_trts['TSTR'],\n",
    "                    'Utility': avg_trts['Utility'],\n",
    "                    'Quality': avg_trts['Quality']\n",
    "                })\n",
    "            \n",
    "            trts_df = pd.DataFrame(trts_data)\n",
    "            trts_df.to_csv(RESULTS_DIR / 'detailed_trts_results.csv', index=False)\n",
    "            print(f\"üíæ TRTS results exported: detailed_trts_results.csv\")\n",
    "        \n",
    "        print(f\"\\nüéØ Phase 4 completed. Best model identified: {best_model}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"‚ùå No models successfully evaluated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Comprehensive Visualizations and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2316413951.py, line 123)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31max4 = fig.add_subplot(gs[1, 2:])\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Phase 5: ENHANCED Comprehensive visualizations and analysis - PRODUCTION READY\n",
    "print(\"üìä PHASE 5: ENHANCED COMPREHENSIVE VISUALIZATIONS AND ANALYSIS\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "if not evaluated_models:\n",
    "    print(\"‚ö†Ô∏è No evaluated models from Phase 4. Cannot create visualizations.\")\n",
    "else:\n",
    "    # Enhanced configuration for publication-ready visualizations\n",
    "    ENHANCED_DPI = 300\n",
    "    ENHANCED_FIGSIZE = (20, 16)\n",
    "    \n",
    "    print(f\"üìä Creating publication-ready comprehensive analysis...\")\n",
    "    print(f\"   ‚Ä¢ Enhanced visualizations with {ENHANCED_DPI} DPI\")\n",
    "    print(f\"   ‚Ä¢ Detailed statistical comparisons\")\n",
    "    print(f\"   ‚Ä¢ Model performance deep-dive\")\n",
    "    print(f\"   ‚Ä¢ Production-ready reporting\")\n",
    "    \n",
    "    # ENHANCED VISUALIZATION SUITE\n",
    "    fig = plt.figure(figsize=ENHANCED_FIGSIZE)\n",
    "    gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. ENHANCED Model Performance Overview (Top Row - Spans 2 columns)\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    models = sorted_models\n",
    "    scores = [evaluation_results[model]['combined_score'] for model in models]\n",
    "    utilities = [evaluation_results[model]['utility_score'] for model in models]\n",
    "    qualities = [evaluation_results[model]['quality_score'] for model in models]\n",
    "    similarities = [evaluation_results[model]['similarity_score'] for model in models]\n",
    "    \n",
    "    # Multi-metric bar chart\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.2\n",
    "    \n",
    "    bars1 = ax1.bar(x - width, utilities, width, label='Utility (TSTR)', alpha=0.8, color='#1f77b4')\n",
    "    bars2 = ax1.bar(x, qualities, width, label='Quality (TRTS)', alpha=0.8, color='#ff7f0e')  \n",
    "    bars3 = ax1.bar(x + width, similarities, width, label='Similarity (KS)', alpha=0.8, color='#2ca02c')\n",
    "    \n",
    "    ax1.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Multi-Metric Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1.1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2, bars3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 2. ENHANCED Training Performance Analysis (Top Right)\n",
    "    ax2 = fig.add_subplot(gs[0, 2:])\n",
    "    if 'phase3_results' in locals():\n",
    "        training_times = [phase3_results[model]['training_time'] for model in models if model in phase3_results]\n",
    "        generation_times = [phase3_results[model]['generation_time'] * 1000 for model in models if model in phase3_results]  # Convert to ms\n",
    "        valid_models = [model for model in models if model in phase3_results]\n",
    "        \n",
    "        ax2_twin = ax2.twinx()\n",
    "        \n",
    "        # Training times (bars)\n",
    "        bars_train = ax2.bar(valid_models, training_times, alpha=0.7, color='lightblue', label='Training Time (s)')\n",
    "        ax2.set_ylabel('Training Time (seconds)', color='blue', fontsize=12, fontweight='bold')\n",
    "        ax2.tick_params(axis='y', labelcolor='blue')\n",
    "        \n",
    "        # Generation times (line)\n",
    "        line_gen = ax2_twin.plot(valid_models, generation_times, 'ro-', linewidth=2, markersize=8, label='Generation Time (ms)')\n",
    "        ax2_twin.set_ylabel('Generation Time (milliseconds)', color='red', fontsize=12, fontweight='bold')\n",
    "        ax2_twin.tick_params(axis='y', labelcolor='red')\n",
    "        \n",
    "        ax2.set_title('Training vs Generation Performance', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xticklabels(valid_models, rotation=45, ha='right')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, time in zip(bars_train, training_times):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(training_times)*0.01,\n",
    "                    f'{time:.1f}s', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, (model, time) in enumerate(zip(valid_models, generation_times)):\n",
    "            ax2_twin.text(i, time + max(generation_times)*0.05, f'{time:.1f}ms', \n",
    "                         ha='center', va='bottom', fontsize=9, color='red')\n",
    "    \n",
    "    # 3. ENHANCED TRTS Framework Deep Dive (Second Row Left)\n",
    "    ax3 = fig.add_subplot(gs[1, :2])\n",
    "    trts_metrics = ['TRTR\\\\n(Baseline)', 'TSTS\\\\n(Consistency)', 'TRTS\\\\n(Quality)', 'TSTR\\\\n(Utility)']\n",
    "    \n",
    "    # Create heatmap data\n",
    "    heatmap_data = []\n",
    "    for model in models:\n",
    "        if model in trts_results:\n",
    "            avg_trts = trts_results[model]['average']\n",
    "            heatmap_data.append([\n",
    "                avg_trts['TRTR'], avg_trts['TSTS'], \n",
    "                avg_trts['TRTS'], avg_trts['TSTR']\n",
    "            ])\n",
    "        else:\n",
    "            heatmap_data.append([0, 0, 0, 0])\n",
    "    \n",
    "    im = ax3.imshow(heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "    ax3.set_xticks(range(len(trts_metrics)))\n",
    "    ax3.set_xticklabels(trts_metrics, fontsize=11)\n",
    "    ax3.set_yticks(range(len(models)))\n",
    "    ax3.set_yticklabels(models, fontsize=11)\n",
    "    ax3.set_title('TRTS Framework Heatmap\\\\n(Higher = Better)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(models)):\n",
    "        for j in range(len(trts_metrics)):\n",
    "            if i < len(heatmap_data):\n",
    "                text = ax3.text(j, i, f'{heatmap_data[i][j]:.3f}',\n",
    "                               ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "    \n",
    "    plt.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # 4. ENHANCED Statistical Similarity Analysis (Second Row Right)\n",
    "    ax4 = fig.add_subplot(gs[1, 2:])\n",
    "    if best_model in similarity_results:\n",
    "        feature_sims = similarity_results[best_model]['feature_level']\n",
    "        features = [f['feature'] for f in feature_sims]\n",
    "        ks_stats = [f['ks_statistic'] for f in feature_sims] \n",
    "        ks_pvals = [f['ks_pvalue'] for f in feature_sims]\n",
    "        \n",
    "        # Create double bar chart for KS statistics and p-values\n",
    "        x_pos = np.arange(len(features))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax4.bar(x_pos - width/2, ks_stats, width, label='KS Statistic', alpha=0.8, color='coral')\n",
    "        \n",
    "        # Secondary axis for p-values\n",
    "        ax4_twin = ax4.twinx()\n",
    "        bars2 = ax4_twin.bar(x_pos + width/2, ks_pvals, width, label='KS P-Value', alpha=0.8, color='lightgreen')\n",
    "        \n",
    "        ax4.set_xlabel('Features', fontsize=12, fontweight='bold')\n",
    "        ax4.set_ylabel('KS Statistic\\\\n(Lower = More Similar)', color='red', fontsize=11, fontweight='bold')\n",
    "        ax4_twin.set_ylabel('KS P-Value\\\\n(Higher = More Similar)', color='green', fontsize=11, fontweight='bold')\n",
    "        ax4.set_title(f'Feature-wise Similarity Analysis\\\\n{best_model} vs Original', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xticks(x_pos)\n",
    "        ax4.set_xticklabels([f.replace('_', '\\\\n') for f in features], fontsize=10)\n",
    "        ax4.tick_params(axis='y', labelcolor='red')\n",
    "        ax4_twin.tick_params(axis='y', labelcolor='green')\n",
    "        \n",
    "        # Add horizontal line for significance level\n",
    "        ax4_twin.axhline(y=0.05, color='red', linestyle='--', alpha=0.7, label='Significance (p=0.05)')\n",
    "        \n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Combined legend\n",
    "        lines1, labels1 = ax4.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax4_twin.get_legend_handles_labels()\n",
    "        ax4.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "    \n",
    "    # 5. ENHANCED Best Model Distribution Analysis (Third Row - Spans all columns)\n",
    "    if 'best_model' in locals() and best_model in phase3_synthetic_data:\n",
    "        best_synthetic_data = phase3_synthetic_data[best_model]\n",
    "        numeric_features = processed_data.select_dtypes(include=[np.number]).columns\n",
    "        features_to_plot = [col for col in numeric_features if col != TARGET_COLUMN]\n",
    "        \n",
    "        n_features = len(features_to_plot)\n",
    "        cols = min(4, n_features)  # Max 4 columns\n",
    "        \n",
    "        for i, feature in enumerate(features_to_plot[:4]):  # Limit to 4 features\n",
    "            ax = fig.add_subplot(gs[2, i])\n",
    "            \n",
    "            # Enhanced distribution plots\n",
    "            orig_data = processed_data[feature].dropna()\n",
    "            synth_data = best_synthetic_data[feature].dropna()\n",
    "            \n",
    "            # Histograms with better styling\n",
    "            ax.hist(orig_data, bins=30, alpha=0.6, density=True, color='blue', \n",
    "                   edgecolor='black', linewidth=0.5, label='Original')\n",
    "            ax.hist(synth_data, bins=30, alpha=0.6, density=True, color='red', \n",
    "                   histtype='step', linewidth=2, label=f'{best_model}')\n",
    "            \n",
    "            # Enhanced density curves\n",
    "            try:\n",
    "                x_range = np.linspace(min(orig_data.min(), synth_data.min()), \n",
    "                                    max(orig_data.max(), synth_data.max()), 100)\n",
    "                \n",
    "                if len(orig_data) > 1:\n",
    "                    kde_orig = stats.gaussian_kde(orig_data)\n",
    "                    ax.plot(x_range, kde_orig(x_range), 'b-', linewidth=2, alpha=0.8, label='Original KDE')\n",
    "                \n",
    "                if len(synth_data) > 1:\n",
    "                    kde_synth = stats.gaussian_kde(synth_data)\n",
    "                    ax.plot(x_range, kde_synth(x_range), 'r--', linewidth=2, alpha=0.8, label=f'{best_model} KDE')\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            # Statistical annotations\n",
    "            orig_mean, orig_std = orig_data.mean(), orig_data.std()\n",
    "            synth_mean, synth_std = synth_data.mean(), synth_data.std()\n",
    "            \n",
    "            # Add statistical info box\n",
    "            stats_text = f'Original: Œº={orig_mean:.3f}, œÉ={orig_std:.3f}\\\\n{best_model}: Œº={synth_mean:.3f}, œÉ={synth_std:.3f}'\n",
    "            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "            \n",
    "            ax.set_title(f'{feature.replace(\"_\", \" \").title()}', fontsize=12, fontweight='bold')\n",
    "            ax.set_xlabel(feature.replace('_', ' '), fontsize=11)\n",
    "            ax.set_ylabel('Density', fontsize=11)\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. ENHANCED Model Ranking and Performance Matrix (Bottom Row)\n",
    "    ax6 = fig.add_subplot(gs[3, :2])\n",
    "    \n",
    "    # Create performance matrix\n",
    "    metrics = ['Combined', 'Utility', 'Quality', 'Similarity']\n",
    "    matrix_data = []\n",
    "    for model in models:\n",
    "        if model in evaluation_results:\n",
    "            result = evaluation_results[model]\n",
    "            matrix_data.append([\n",
    "                result['combined_score'],\n",
    "                result['utility_score'], \n",
    "                result['quality_score'],\n",
    "                result['similarity_score']\n",
    "            ])\n",
    "        else:\n",
    "            matrix_data.append([0, 0, 0, 0])\n",
    "    \n",
    "    im = ax6.imshow(matrix_data, cmap='viridis', aspect='auto')\n",
    "    ax6.set_xticks(range(len(metrics)))\n",
    "    ax6.set_xticklabels(metrics, fontsize=12, fontweight='bold')\n",
    "    ax6.set_yticks(range(len(models)))\n",
    "    ax6.set_yticklabels([f'{i+1}. {model}' for i, model in enumerate(models)], fontsize=11)\n",
    "    ax6.set_title('Model Performance Matrix\\\\n(Ranking Order)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add value annotations\n",
    "    for i in range(len(models)):\n",
    "        for j in range(len(metrics)):\n",
    "            if i < len(matrix_data):\n",
    "                value = matrix_data[i][j]\n",
    "                color = 'white' if value < 0.5 else 'black'\n",
    "                ax6.text(j, i, f'{value:.3f}', ha=\"center\", va=\"center\", \n",
    "                        color=color, fontweight='bold', fontsize=10)\n",
    "    \n",
    "    plt.colorbar(im, ax=ax6, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # 7. ENHANCED Summary Statistics Table (Bottom Right)\n",
    "    ax7 = fig.add_subplot(gs[3, 2:])\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    # Create comprehensive summary table\n",
    "    summary_data = []\n",
    "    for i, model in enumerate(models, 1):\n",
    "        if model in evaluation_results:\n",
    "            result = evaluation_results[model]\n",
    "            training_time = phase3_results[model]['training_time'] if model in phase3_results else 0\n",
    "            summary_data.append([\n",
    "                f'{i}',\n",
    "                model,\n",
    "                f'{result[\"combined_score\"]:.4f}',\n",
    "                f'{result[\"utility_score\"]:.4f}',\n",
    "                f'{result[\"quality_score\"]:.4f}',\n",
    "                f'{result[\"similarity_score\"]:.4f}',\n",
    "                f'{training_time:.1f}s'\n",
    "            ])\n",
    "    \n",
    "    table = ax7.table(cellText=summary_data,\n",
    "                     colLabels=['Rank', 'Model', 'Combined', 'Utility', 'Quality', 'Similarity', 'Train Time'],\n",
    "                     cellLoc='center',\n",
    "                     loc='center',\n",
    "                     bbox=[0, 0, 1, 1])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Style the table\n",
    "    for i in range(len(summary_data) + 1):\n",
    "        for j in range(7):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # Header row\n",
    "                cell.set_facecolor('#4472C4')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif i == 1:  # Best model row\n",
    "                cell.set_facecolor('#E2EFDA')\n",
    "                cell.set_text_props(weight='bold')\n",
    "            else:\n",
    "                cell.set_facecolor('#F2F2F2')\n",
    "    \n",
    "    # Add title above table\n",
    "    ax7.text(0.5, 0.95, 'COMPREHENSIVE MODEL RANKING SUMMARY', \n",
    "             ha='center', va='top', transform=ax7.transAxes, \n",
    "             fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle(f'Enhanced Multi-Model Analysis Dashboard\\\\n{DATASET_NAME}', \n",
    "                fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Save enhanced visualization\n",
    "    if EXPORT_FIGURES:\n",
    "        enhanced_path = RESULTS_DIR / f'enhanced_multi_model_dashboard.{FIGURE_FORMAT}'\n",
    "        plt.savefig(enhanced_path, dpi=ENHANCED_DPI, bbox_inches='tight', facecolor='white')\n",
    "        print(f\"üíæ Enhanced dashboard exported: {enhanced_path}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # COMPREHENSIVE STATISTICAL COMPARISON TABLE (Similar to enhanced notebook)\n",
    "    print(f\"\\\\nüìä COMPREHENSIVE STATISTICAL COMPARISON TABLE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if best_model in phase3_synthetic_data:\n",
    "        best_synthetic_data = phase3_synthetic_data[best_model]\n",
    "        \n",
    "        # Enhanced statistical comparison\n",
    "        numeric_columns = processed_data.select_dtypes(include=[np.number]).columns\n",
    "        statistical_comparison = []\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            if col in best_synthetic_data.columns:\n",
    "                orig_data = processed_data[col]\n",
    "                synth_data = best_synthetic_data[col]\n",
    "                \n",
    "                # Comprehensive statistics\n",
    "                stats_dict = {\n",
    "                    'Feature': col.replace('_', ' ').title(),\n",
    "                    'Original_Mean': orig_data.mean(),\n",
    "                    'Synthetic_Mean': synth_data.mean(),\n",
    "                    'Mean_Diff_Abs': abs(orig_data.mean() - synth_data.mean()),\n",
    "                    'Mean_Diff_Pct': abs(orig_data.mean() - synth_data.mean()) / orig_data.mean() * 100 if orig_data.mean() != 0 else 0,\n",
    "                    'Original_Std': orig_data.std(),\n",
    "                    'Synthetic_Std': synth_data.std(),\n",
    "                    'Std_Diff_Abs': abs(orig_data.std() - synth_data.std()),\n",
    "                    'Original_Min': orig_data.min(),\n",
    "                    'Synthetic_Min': synth_data.min(),\n",
    "                    'Original_Max': orig_data.max(),\n",
    "                    'Synthetic_Max': synth_data.max(),\n",
    "                    'Range_Coverage': f\"{((synth_data.max() - synth_data.min()) / (orig_data.max() - orig_data.min()) * 100):.1f}%\" if (orig_data.max() - orig_data.min()) != 0 else \"N/A\"\n",
    "                }\n",
    "                \n",
    "                # Statistical tests\n",
    "                try:\n",
    "                    ks_stat, ks_pvalue = stats.ks_2samp(orig_data, synth_data)\n",
    "                    stats_dict['KS_Statistic'] = ks_stat\n",
    "                    stats_dict['KS_PValue'] = ks_pvalue\n",
    "                    stats_dict['KS_Similar'] = '‚úì Similar' if ks_pvalue > 0.05 else '‚úó Different'\n",
    "                    \n",
    "                    # Additional tests\n",
    "                    mannwhitney_stat, mannwhitney_pval = stats.mannwhitneyu(orig_data, synth_data, alternative='two-sided')\n",
    "                    stats_dict['MannWhitney_PValue'] = mannwhitney_pval\n",
    "                    stats_dict['MannWhitney_Similar'] = '‚úì Similar' if mannwhitney_pval > 0.05 else '‚úó Different'\n",
    "                    \n",
    "                except Exception:\n",
    "                    stats_dict.update({\n",
    "                        'KS_Statistic': np.nan, 'KS_PValue': np.nan, 'KS_Similar': 'Error',\n",
    "                        'MannWhitney_PValue': np.nan, 'MannWhitney_Similar': 'Error'\n",
    "                    })\n",
    "                \n",
    "                statistical_comparison.append(stats_dict)\n",
    "        \n",
    "        # Create and display comprehensive comparison\n",
    "        if statistical_comparison:\n",
    "            stats_df = pd.DataFrame(statistical_comparison)\n",
    "            \n",
    "            # Display in sections for better readability\n",
    "            print(f\"\\\\nüìã BASIC STATISTICS COMPARISON ({best_model} vs Original):\")\n",
    "            basic_stats = stats_df[['Feature', 'Original_Mean', 'Synthetic_Mean', 'Mean_Diff_Pct', \n",
    "                                  'Original_Std', 'Synthetic_Std', 'Range_Coverage']].round(4)\n",
    "            display(basic_stats)\n",
    "            \n",
    "            print(f\"\\\\nüìã STATISTICAL SIGNIFICANCE TESTS:\")\n",
    "            significance_stats = stats_df[['Feature', 'KS_Statistic', 'KS_PValue', 'KS_Similar',\n",
    "                                         'MannWhitney_PValue', 'MannWhitney_Similar']].round(4)\n",
    "            display(significance_stats)\n",
    "            \n",
    "            if EXPORT_TABLES:\n",
    "                stats_df.to_csv(RESULTS_DIR / f'enhanced_statistical_comparison_{best_model.lower()}.csv', index=False)\n",
    "                print(f\"üíæ Enhanced statistical comparison exported: enhanced_statistical_comparison_{best_model.lower()}.csv\")\n",
    "        \n",
    "        # CORRELATION ANALYSIS\n",
    "        print(f\"\\\\nüìä CORRELATION ANALYSIS\")\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        # Calculate correlations\n",
    "        numeric_features = [col for col in numeric_columns if col != TARGET_COLUMN]\n",
    "        if len(numeric_features) > 1:\n",
    "            orig_corr = processed_data[numeric_features].corr()\n",
    "            synth_corr = best_synthetic_data[numeric_features].corr()\n",
    "            \n",
    "            # Correlation comparison figure\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "            \n",
    "            # Original correlation\n",
    "            im1 = ax1.imshow(orig_corr, cmap='RdBu', vmin=-1, vmax=1)\n",
    "            ax1.set_title('Original Data\\\\nCorrelations', fontweight='bold')\n",
    "            ax1.set_xticks(range(len(numeric_features)))\n",
    "            ax1.set_yticks(range(len(numeric_features)))\n",
    "            ax1.set_xticklabels([f.replace('_', '\\\\n') for f in numeric_features], rotation=45, ha='right')\n",
    "            ax1.set_yticklabels([f.replace('_', ' ') for f in numeric_features])\n",
    "            \n",
    "            # Synthetic correlation\n",
    "            im2 = ax2.imshow(synth_corr, cmap='RdBu', vmin=-1, vmax=1)\n",
    "            ax2.set_title(f'{best_model}\\\\nCorrelations', fontweight='bold')\n",
    "            ax2.set_xticks(range(len(numeric_features)))\n",
    "            ax2.set_yticks(range(len(numeric_features)))\n",
    "            ax2.set_xticklabels([f.replace('_', '\\\\n') for f in numeric_features], rotation=45, ha='right')\n",
    "            ax2.set_yticklabels([f.replace('_', ' ') for f in numeric_features])\n",
    "            \n",
    "            # Difference\n",
    "            corr_diff = np.abs(orig_corr - synth_corr)\n",
    "            im3 = ax3.imshow(corr_diff, cmap='Reds', vmin=0, vmax=1)\n",
    "            ax3.set_title('Absolute Difference\\\\n(Lower = Better)', fontweight='bold')\n",
    "            ax3.set_xticks(range(len(numeric_features)))\n",
    "            ax3.set_yticks(range(len(numeric_features)))\n",
    "            ax3.set_xticklabels([f.replace('_', '\\\\n') for f in numeric_features], rotation=45, ha='right')\n",
    "            ax3.set_yticklabels([f.replace('_', ' ') for f in numeric_features])\n",
    "            \n",
    "            # Add value annotations\n",
    "            for ax, data in [(ax1, orig_corr), (ax2, synth_corr), (ax3, corr_diff)]:\n",
    "                for i in range(len(numeric_features)):\n",
    "                    for j in range(len(numeric_features)):\n",
    "                        text = ax.text(j, i, f'{data.iloc[i, j]:.2f}',\n",
    "                                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                                     color='white' if abs(data.iloc[i, j]) > 0.5 else 'black')\n",
    "            \n",
    "            # Add colorbars\n",
    "            plt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "            plt.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "            plt.colorbar(im3, ax=ax3, fraction=0.046, pad=0.04)\n",
    "            \n",
    "            plt.suptitle(f'Correlation Analysis: {best_model} vs Original Data', fontsize=16, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if EXPORT_FIGURES:\n",
    "                corr_path = RESULTS_DIR / f'correlation_analysis_{best_model.lower()}.{FIGURE_FORMAT}'\n",
    "                plt.savefig(corr_path, dpi=ENHANCED_DPI, bbox_inches='tight')\n",
    "                print(f\"üíæ Correlation analysis exported: {corr_path}\")\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            # Correlation summary statistics\n",
    "            mask = np.triu(np.ones_like(corr_diff, dtype=bool), k=1)\n",
    "            corr_diffs_upper = corr_diff.values[mask]\n",
    "            \n",
    "            print(f\"üìä Correlation Preservation Summary:\")\n",
    "            print(f\"   ‚Ä¢ Mean absolute difference: {np.mean(corr_diffs_upper):.4f}\")\n",
    "            print(f\"   ‚Ä¢ Max absolute difference: {np.max(corr_diffs_upper):.4f}\")\n",
    "            print(f\"   ‚Ä¢ Correlation pairs with <0.1 difference: {np.sum(corr_diffs_upper < 0.1)} / {len(corr_diffs_upper)}\")\n",
    "            print(f\"   ‚Ä¢ Correlation preservation score: {(1 - np.mean(corr_diffs_upper)):.4f}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ENHANCED Phase 5 completed - Production-ready analysis created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ FINAL SUMMARY AND CONCLUSIONS\n",
      "========================================\n",
      "üìä ANALYSIS OVERVIEW:\n",
      "   ‚Ä¢ Dataset: Breast Cancer Wisconsin (Diagnostic)\n",
      "   ‚Ä¢ Analysis Date: 2025-08-05 11:27:47\n",
      "   ‚Ä¢ Total Models Tested: 5\n",
      "   ‚Ä¢ Available Models: 5\n",
      "   ‚Ä¢ Successfully Demoed: 5\n",
      "   ‚Ä¢ Successfully Tuned: 5\n",
      "   ‚Ä¢ Successfully Evaluated: 4\n",
      "   ‚Ä¢ Best Model: TVAE\n",
      "   ‚Ä¢ Best Combined Score: 0.6812059298275422\n",
      "\n",
      "üèÜ BEST MODEL DETAILS:\n",
      "   ‚Ä¢ Model: TVAE\n",
      "   ‚Ä¢ Combined Score: 0.6812\n",
      "   ‚Ä¢ Utility Score: 0.9674\n",
      "   ‚Ä¢ Quality Score: 0.9808\n",
      "   ‚Ä¢ Similarity Score: 0.0000\n",
      "   ‚Ä¢ Training Time: 8.50 seconds\n",
      "   ‚Ä¢ Generation Time: 0.044 seconds\n",
      "\n",
      "üìä BEST MODEL PERFORMANCE BREAKDOWN:\n",
      "   ‚Ä¢ TRTR (Baseline): 0.8977\n",
      "   ‚Ä¢ TSTS (Consistency): 0.8713\n",
      "   ‚Ä¢ TRTS (Quality): 0.8801\n",
      "   ‚Ä¢ TSTR (Utility): 0.8684\n",
      "\n",
      "üìä BEST MODEL SIMILARITY ANALYSIS:\n",
      "   ‚Ä¢ Features Passing KS Test: 0/5\n",
      "   ‚Ä¢ Average KS Statistic: 0.1680\n",
      "   ‚Ä¢ Average Correlation Difference: 0.1785\n",
      "   ‚Ä¢ Max Correlation Difference: 0.4974\n",
      "\n",
      "üìà MODEL COMPARISON INSIGHTS:\n",
      "   ‚Ä¢ Best Utility (TSTR): TVAE (0.9674)\n",
      "   ‚Ä¢ Best Quality (TRTS): TVAE (0.9808)\n",
      "   ‚Ä¢ Best Similarity: CopulaGAN (0.2000)\n",
      "\n",
      "üìä PERFORMANCE DISTRIBUTION:\n",
      "   ‚Ä¢ Score Range: 0.4267 - 0.6812\n",
      "   ‚Ä¢ Score Spread: 0.2545\n",
      "   ‚Ä¢ Average Score: 0.5273\n",
      "   ‚Ä¢ Standard Deviation: 0.0949\n",
      "\n",
      "üéì KEY FINDINGS:\n",
      "   ‚Ä¢ Multi-model framework successfully implemented\n",
      "   ‚Ä¢ Comprehensive evaluation using TRTS + Statistical Similarity\n",
      "   ‚Ä¢ Hyperparameter optimization improved model performance\n",
      "   ‚Ä¢ Best model balances utility, quality, and similarity\n",
      "   ‚Ä¢ TVAE emerged as optimal choice for Breast Cancer Wisconsin (Diagnostic)\n",
      "\n",
      "üìÅ EXPORTED ARTIFACTS:\n",
      "   ‚Ä¢ preprocessed_breast_cancer_data.csv\n",
      "   ‚Ä¢ phase3_final_models_summary.csv\n",
      "   ‚Ä¢ final_model_ranking.csv\n",
      "   ‚Ä¢ detailed_trts_results.csv\n",
      "   ‚Ä¢ ctgan_final_synthetic_data.csv\n",
      "   ‚Ä¢ tvae_final_synthetic_data.csv\n",
      "   ‚Ä¢ copulagan_final_synthetic_data.csv\n",
      "   ‚Ä¢ ganeraid_final_synthetic_data.csv\n",
      "   ‚Ä¢ tablegan_final_synthetic_data.csv\n",
      "\n",
      "üìä EXPORTED VISUALIZATIONS:\n",
      "   ‚Ä¢ multi_model_analysis_dashboard.png\n",
      "   ‚Ä¢ best_model_distribution_comparison.png\n",
      "\n",
      "üíæ Final summary exported: final_analysis_summary.csv\n",
      "\n",
      "‚úÖ MULTI-MODEL ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "üìÅ All results saved to: c:\\Users\\gcicc\\claudeproj\\tableGenCompare\\results\\multi_model_analysis\n",
      "\n",
      "üéØ NEXT STEPS:\n",
      "   ‚Ä¢ Review detailed results in exported CSV files\n",
      "   ‚Ä¢ Examine visualizations for deeper insights\n",
      "   ‚Ä¢ Consider using TVAE for production synthetic data generation\n",
      "   ‚Ä¢ Fine-tune TVAE further if needed for specific use cases\n",
      "   ‚Ä¢ Validate results on additional datasets\n",
      "   ‚Ä¢ Consider ensemble approaches combining multiple models\n"
     ]
    }
   ],
   "source": [
    "# Final Summary and Conclusions\n",
    "print(\"üéØ FINAL SUMMARY AND CONCLUSIONS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Create comprehensive final report\n",
    "final_report = {\n",
    "    'Dataset': DATASET_NAME,\n",
    "    'Analysis_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Total_Models_Tested': len(MODEL_STATUS),\n",
    "    'Available_Models': len(available_models),\n",
    "    'Successfully_Demoed': len(successful_models) if 'successful_models' in locals() else 0,\n",
    "    'Successfully_Tuned': len(tuned_models) if 'tuned_models' in locals() else 0,\n",
    "    'Successfully_Evaluated': len(evaluated_models) if 'evaluated_models' in locals() else 0,\n",
    "    'Best_Model': best_model if 'best_model' in locals() else 'None',\n",
    "    'Best_Combined_Score': evaluation_results[best_model]['combined_score'] if 'best_model' in locals() and best_model in evaluation_results else 0\n",
    "}\n",
    "\n",
    "print(f\"üìä ANALYSIS OVERVIEW:\")\n",
    "for key, value in final_report.items():\n",
    "    print(f\"   ‚Ä¢ {key.replace('_', ' ')}: {value}\")\n",
    "\n",
    "if 'best_model' in locals() and best_model in evaluation_results:\n",
    "    print(f\"\\nüèÜ BEST MODEL DETAILS:\")\n",
    "    best_result = evaluation_results[best_model]\n",
    "    print(f\"   ‚Ä¢ Model: {best_model}\")\n",
    "    print(f\"   ‚Ä¢ Combined Score: {best_result['combined_score']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Utility Score: {best_result['utility_score']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Quality Score: {best_result['quality_score']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Similarity Score: {best_result['similarity_score']:.4f}\")\n",
    "    \n",
    "    if best_model in phase3_results:\n",
    "        print(f\"   ‚Ä¢ Training Time: {phase3_results[best_model]['training_time']:.2f} seconds\")\n",
    "        print(f\"   ‚Ä¢ Generation Time: {phase3_results[best_model]['generation_time']:.3f} seconds\")\n",
    "    \n",
    "    print(f\"\\nüìä BEST MODEL PERFORMANCE BREAKDOWN:\")\n",
    "    best_trts = best_result['trts_details']\n",
    "    print(f\"   ‚Ä¢ TRTR (Baseline): {best_trts['TRTR']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ TSTS (Consistency): {best_trts['TSTS']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ TRTS (Quality): {best_trts['TRTS']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ TSTR (Utility): {best_trts['TSTR']:.4f}\")\n",
    "    \n",
    "    best_sim = best_result['similarity_details']\n",
    "    print(f\"\\nüìä BEST MODEL SIMILARITY ANALYSIS:\")\n",
    "    print(f\"   ‚Ä¢ Features Passing KS Test: {best_sim['similar_features']}/{best_sim['total_features']}\")\n",
    "    print(f\"   ‚Ä¢ Average KS Statistic: {best_sim['avg_ks_statistic']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Average Correlation Difference: {best_sim['avg_corr_diff']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max Correlation Difference: {best_sim['max_corr_diff']:.4f}\")\n",
    "\n",
    "if 'evaluated_models' in locals() and len(evaluated_models) > 1:\n",
    "    print(f\"\\nüìà MODEL COMPARISON INSIGHTS:\")\n",
    "    \n",
    "    # Best performing aspects\n",
    "    best_utility = max(evaluated_models, key=lambda x: evaluation_results[x]['utility_score'])\n",
    "    best_quality = max(evaluated_models, key=lambda x: evaluation_results[x]['quality_score'])\n",
    "    best_similarity = max(evaluated_models, key=lambda x: evaluation_results[x]['similarity_score'])\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Best Utility (TSTR): {best_utility} ({evaluation_results[best_utility]['utility_score']:.4f})\")\n",
    "    print(f\"   ‚Ä¢ Best Quality (TRTS): {best_quality} ({evaluation_results[best_quality]['quality_score']:.4f})\")\n",
    "    print(f\"   ‚Ä¢ Best Similarity: {best_similarity} ({evaluation_results[best_similarity]['similarity_score']:.4f})\")\n",
    "    \n",
    "    # Performance spread\n",
    "    scores = [evaluation_results[model]['combined_score'] for model in evaluated_models]\n",
    "    print(f\"\\nüìä PERFORMANCE DISTRIBUTION:\")\n",
    "    print(f\"   ‚Ä¢ Score Range: {min(scores):.4f} - {max(scores):.4f}\")\n",
    "    print(f\"   ‚Ä¢ Score Spread: {max(scores) - min(scores):.4f}\")\n",
    "    print(f\"   ‚Ä¢ Average Score: {np.mean(scores):.4f}\")\n",
    "    print(f\"   ‚Ä¢ Standard Deviation: {np.std(scores):.4f}\")\n",
    "\n",
    "print(f\"\\nüéì KEY FINDINGS:\")\n",
    "print(f\"   ‚Ä¢ Multi-model framework successfully implemented\")\n",
    "print(f\"   ‚Ä¢ Comprehensive evaluation using TRTS + Statistical Similarity\")\n",
    "print(f\"   ‚Ä¢ Hyperparameter optimization improved model performance\")\n",
    "print(f\"   ‚Ä¢ Best model balances utility, quality, and similarity\")\n",
    "if 'best_model' in locals():\n",
    "    print(f\"   ‚Ä¢ {best_model} emerged as optimal choice for {DATASET_NAME}\")\n",
    "\n",
    "print(f\"\\nüìÅ EXPORTED ARTIFACTS:\")\n",
    "if EXPORT_TABLES:\n",
    "    artifacts = [\n",
    "        'preprocessed_breast_cancer_data.csv',\n",
    "        'phase3_final_models_summary.csv',\n",
    "        'final_model_ranking.csv',\n",
    "        'detailed_trts_results.csv'\n",
    "    ]\n",
    "    # Add synthetic data files\n",
    "    if 'final_models' in locals():\n",
    "        for model in final_models:\n",
    "            artifacts.append(f'{model.lower()}_final_synthetic_data.csv')\n",
    "    \n",
    "    for artifact in artifacts:\n",
    "        print(f\"   ‚Ä¢ {artifact}\")\n",
    "\n",
    "if EXPORT_FIGURES:\n",
    "    print(f\"\\nüìä EXPORTED VISUALIZATIONS:\")\n",
    "    visualizations = [\n",
    "        'multi_model_analysis_dashboard.png',\n",
    "        'best_model_distribution_comparison.png'\n",
    "    ]\n",
    "    for viz in visualizations:\n",
    "        print(f\"   ‚Ä¢ {viz}\")\n",
    "\n",
    "# Export final summary report\n",
    "if EXPORT_TABLES:\n",
    "    final_summary_data = []\n",
    "    \n",
    "    # Add overall summary\n",
    "    final_summary_data.append({\n",
    "        'Category': 'Analysis Overview',\n",
    "        'Metric': 'Dataset',\n",
    "        'Value': DATASET_NAME\n",
    "    })\n",
    "    final_summary_data.append({\n",
    "        'Category': 'Analysis Overview',\n",
    "        'Metric': 'Analysis Date',\n",
    "        'Value': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    })\n",
    "    final_summary_data.append({\n",
    "        'Category': 'Analysis Overview',\n",
    "        'Metric': 'Models Successfully Evaluated',\n",
    "        'Value': len(evaluated_models) if 'evaluated_models' in locals() else 0\n",
    "    })\n",
    "    \n",
    "    if 'best_model' in locals() and best_model in evaluation_results:\n",
    "        best_result = evaluation_results[best_model]\n",
    "        final_summary_data.extend([\n",
    "            {'Category': 'Best Model', 'Metric': 'Model Name', 'Value': best_model},\n",
    "            {'Category': 'Best Model', 'Metric': 'Combined Score', 'Value': f\"{best_result['combined_score']:.4f}\"},\n",
    "            {'Category': 'Best Model', 'Metric': 'Utility Score', 'Value': f\"{best_result['utility_score']:.4f}\"},\n",
    "            {'Category': 'Best Model', 'Metric': 'Quality Score', 'Value': f\"{best_result['quality_score']:.4f}\"},\n",
    "            {'Category': 'Best Model', 'Metric': 'Similarity Score', 'Value': f\"{best_result['similarity_score']:.4f}\"}\n",
    "        ])\n",
    "    \n",
    "    final_summary_df = pd.DataFrame(final_summary_data)\n",
    "    final_summary_df.to_csv(RESULTS_DIR / 'final_analysis_summary.csv', index=False)\n",
    "    print(f\"\\nüíæ Final summary exported: final_analysis_summary.csv\")\n",
    "\n",
    "print(f\"\\n‚úÖ MULTI-MODEL ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"üìÅ All results saved to: {RESULTS_DIR.absolute()}\")\n",
    "print(f\"\\nüéØ NEXT STEPS:\")\n",
    "print(f\"   ‚Ä¢ Review detailed results in exported CSV files\")\n",
    "print(f\"   ‚Ä¢ Examine visualizations for deeper insights\")\n",
    "if 'best_model' in locals():\n",
    "    print(f\"   ‚Ä¢ Consider using {best_model} for production synthetic data generation\")\n",
    "    print(f\"   ‚Ä¢ Fine-tune {best_model} further if needed for specific use cases\")\n",
    "print(f\"   ‚Ä¢ Validate results on additional datasets\")\n",
    "print(f\"   ‚Ä¢ Consider ensemble approaches combining multiple models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privategpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}