{
 "cells": [
  {
   "cell_type": "code",
   "id": "6tiss5lfgnr",
   "source": "# CTGAN Hyperparameter Optimization\\nprint(\\\"ðŸ”„ CTGAN Hyperparameter Optimization\\\")\\nprint(\\\"=\\\" * 50)\\n\\ndef ctgan_objective(trial):\\n    \\\"\\\"\\\"Optuna objective function for CTGAN\\\"\\\"\\\"\\n    \\n    # Get hyperparameter space from model\\n    ctgan_space = CTGANModel().get_hyperparameter_space()\\n    \\n    # Sample hyperparameters\\n    params = {\\n        'epochs': trial.suggest_int('epochs', 100, 1000, step=50),\\n        'batch_size': trial.suggest_categorical('batch_size', [64, 128, 256, 512]),\\n        'generator_lr': trial.suggest_loguniform('generator_lr', 1e-5, 1e-3),\\n        'discriminator_lr': trial.suggest_loguniform('discriminator_lr', 1e-5, 1e-3),\\n        'generator_dim': trial.suggest_categorical('generator_dim', \\n            [(128, 128), (256, 256), (256, 128, 64), (512, 256, 128)]),\\n        'discriminator_dim': trial.suggest_categorical('discriminator_dim',\\n            [(128, 128), (256, 256), (256, 128, 64), (512, 256, 128)]),\\n        'pac': trial.suggest_int('pac', 5, 20),\\n        'embedding_dim': trial.suggest_int('embedding_dim', 64, 256, step=32),\\n        'generator_decay': trial.suggest_loguniform('generator_decay', 1e-6, 1e-3),\\n        'discriminator_decay': trial.suggest_loguniform('discriminator_decay', 1e-6, 1e-3)\\n    }\\n    \\n    try:\\n        # Initialize and train model\\n        model = CTGANModel()\\n        model.train(data, **params)\\n        \\n        # Generate synthetic data\\n        synthetic_data = model.generate(len(data))\\n        \\n        # Calculate objective score\\n        objective_score, sim_score, acc_score = enhanced_objective_function_v2(\\n            data, synthetic_data, target_column)\\n        \\n        # Store additional metrics\\n        trial.set_user_attr('similarity_score', sim_score)\\n        trial.set_user_attr('accuracy_score', acc_score)\\n        \\n        return objective_score\\n    \\n    except Exception as e:\\n        print(f\\\"Trial failed: {e}\\\")\\n        return 0.0\\n\\n# Run CTGAN optimization\\nctgan_study = optuna.create_study(direction='maximize', study_name='CTGAN_Optimization')\\nprint(\\\"Starting CTGAN optimization (20 trials)...\\\")\\nctgan_study.optimize(ctgan_objective, n_trials=20, timeout=3600)  # 1 hour timeout\\n\\n# Display results\\nprint(f\\\"\\\\nâœ… CTGAN Optimization Complete:\\\")\\nprint(f\\\"   - Best objective score: {ctgan_study.best_value:.4f}\\\")\\nprint(f\\\"   - Best parameters: {ctgan_study.best_params}\\\")\\nprint(f\\\"   - Best similarity: {ctgan_study.best_trial.user_attrs.get('similarity_score', 'N/A')}\\\")\\nprint(f\\\"   - Best accuracy: {ctgan_study.best_trial.user_attrs.get('accuracy_score', 'N/A')}\\\")\\n\\n# Store best parameters\\nctgan_best_params = ctgan_study.best_params\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9fx4pbjgac7",
   "source": "### 2.2 CTGAN Hyperparameter Optimization",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "main-title",
   "metadata": {},
   "source": [
    "# Multi-Model Synthetic Data Generation: Breast Cancer Dataset\n",
    "\n",
    "## Comprehensive Demo and Hyperparameter Tuning of 5 Models\n",
    "\n",
    "This notebook demonstrates a comprehensive synthetic data generation framework using five state-of-the-art models:\n",
    "- **CTGAN** (Conditional Tabular GAN)\n",
    "- **TVAE** (Tabular Variational Autoencoder)\n",
    "- **CopulaGAN** (Copula-based GAN)\n",
    "- **TableGAN** (Table-focused GAN)\n",
    "- **GANerAid** (Healthcare-focused GAN)\n",
    "\n",
    "### Enhanced Framework Features\n",
    "\n",
    "- **Enhanced Objective Function**: 60% similarity + 40% accuracy weighting\n",
    "- **Comprehensive Hyperparameter Optimization**: Using Optuna with production-ready parameter spaces\n",
    "- **Advanced Similarity Metrics**: Earth Mover's Distance and correlation-based analysis\n",
    "- **Clinical Focus**: Designed for healthcare applications with privacy considerations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "import optuna\n",
    "from pathlib import Path\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import model implementations\n",
    "from src.models.implementations.ctgan_model import CTGANModel\n",
    "from src.models.implementations.tvae_model import TVAEModel\n",
    "from src.models.implementations.copulagan_model import CopulaGANModel\n",
    "from src.models.implementations.tablegan_model import TableGANModel\n",
    "from src.models.implementations.ganeraid_model import GANerAidModel\n",
    "\n",
    "# Import optimization and evaluation functions\n",
    "from src.optimization.objective_functions import enhanced_objective_function\n",
    "from src.evaluation.metrics import calculate_similarity_metrics, evaluate_model_performance\n",
    "from src.visualization.training_history_plotter import plot_training_history\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Create output directories\n",
    "output_dir = Path('outputs/multi_model_results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('âœ… Setup complete - All libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "data_file = 'data/Breast_cancer_data.csv'\n",
    "target_column = 'diagnosis'\n",
    "\n",
    "# Load and examine the data\n",
    "data = pd.read_csv(data_file)\n",
    "print(f'Dataset shape: {data.shape}')\n",
    "print(f'Target column: {target_column}')\n",
    "print(f'Target distribution:')\n",
    "print(data[target_column].value_counts())\n",
    "\n",
    "# Display basic statistics\n",
    "print(f'\\nDataset Info:')\n",
    "data.info()\n",
    "\n",
    "# Display first few rows\n",
    "print(f'\\nFirst 5 rows:')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase1-demo",
   "metadata": {},
   "source": [
    "## Phase 1: Demo All Models with Default Parameters\n",
    "\n",
    "Before hyperparameter optimization, we demonstrate each model with default parameters to establish baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ctgan-demo",
   "metadata": {},
   "source": [
    "### 1.1 CTGAN Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ctgan-demo-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTGAN Demo with default parameters\n",
    "print(\"ðŸ”„ CTGAN Demo - Default Parameters\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initialize CTGAN model\n",
    "ctgan_model = CTGANModel()\n",
    "\n",
    "# Train with minimal parameters for demo\n",
    "demo_params = {'epochs': 50, 'batch_size': 100}\n",
    "start_time = time.time()\n",
    "ctgan_model.train(data, **demo_params)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Generate synthetic data\n",
    "demo_samples = len(data)  # Same size as original dataset\n",
    "synthetic_data_ctgan = ctgan_model.generate(demo_samples)\n",
    "\n",
    "print(f\"âœ… CTGAN Demo Complete:\")\n",
    "print(f\"   - Training time: {train_time:.2f} seconds\")\n",
    "print(f\"   - Generated samples: {len(synthetic_data_ctgan)}\")\n",
    "print(f\"   - Original shape: {data.shape}\")\n",
    "print(f\"   - Synthetic shape: {synthetic_data_ctgan.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tvae-demo",
   "metadata": {},
   "source": [
    "### 1.2 TVAE Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tvae-demo-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TVAE Demo with default parameters\n",
    "print(\"ðŸ”„ TVAE Demo - Default Parameters\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initialize TVAE model\n",
    "tvae_model = TVAEModel()\n",
    "\n",
    "# Train with minimal parameters for demo\n",
    "demo_params = {'epochs': 50, 'batch_size': 100}\n",
    "start_time = time.time()\n",
    "tvae_model.train(data, **demo_params)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Generate synthetic data\n",
    "synthetic_data_tvae = tvae_model.generate(demo_samples)\n",
    "\n",
    "print(f\"âœ… TVAE Demo Complete:\")\n",
    "print(f\"   - Training time: {train_time:.2f} seconds\")\n",
    "print(f\"   - Generated samples: {len(synthetic_data_tvae)}\")\n",
    "print(f\"   - Original shape: {data.shape}\")\n",
    "print(f\"   - Synthetic shape: {synthetic_data_tvae.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copulagan-demo",
   "metadata": {},
   "source": [
    "### 1.3 CopulaGAN Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copulagan-demo-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CopulaGAN Demo with default parameters\n",
    "print(\"ðŸ”„ CopulaGAN Demo - Default Parameters\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initialize CopulaGAN model\n",
    "copulagan_model = CopulaGANModel()\n",
    "\n",
    "# Train with minimal parameters for demo\n",
    "demo_params = {'epochs': 50, 'batch_size': 100}\n",
    "start_time = time.time()\n",
    "copulagan_model.train(data, **demo_params)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Generate synthetic data\n",
    "synthetic_data_copulagan = copulagan_model.generate(demo_samples)\n",
    "\n",
    "print(f\"âœ… CopulaGAN Demo Complete:\")\n",
    "print(f\"   - Training time: {train_time:.2f} seconds\")\n",
    "print(f\"   - Generated samples: {len(synthetic_data_copulagan)}\")\n",
    "print(f\"   - Original shape: {data.shape}\")\n",
    "print(f\"   - Synthetic shape: {synthetic_data_copulagan.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tablegan-demo",
   "metadata": {},
   "source": [
    "### 1.4 TableGAN Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tablegan-demo-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TableGAN Demo with default parameters\n",
    "print(\"ðŸ”„ TableGAN Demo - Default Parameters\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initialize TableGAN model\n",
    "tablegan_model = TableGANModel()\n",
    "\n",
    "# Train with minimal parameters for demo\n",
    "demo_params = {'epochs': 50, 'batch_size': 100}\n",
    "start_time = time.time()\n",
    "tablegan_model.train(data, **demo_params)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Generate synthetic data\n",
    "synthetic_data_tablegan = tablegan_model.generate(demo_samples)\n",
    "\n",
    "print(f\"âœ… TableGAN Demo Complete:\")\n",
    "print(f\"   - Training time: {train_time:.2f} seconds\")\n",
    "print(f\"   - Generated samples: {len(synthetic_data_tablegan)}\")\n",
    "print(f\"   - Original shape: {data.shape}\")\n",
    "print(f\"   - Synthetic shape: {synthetic_data_tablegan.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ganeraid-demo",
   "metadata": {},
   "source": [
    "### 1.5 GANerAid Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ganeraid-demo-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GANerAid Demo with default parameters\n",
    "print(\"ðŸ”„ GANerAid Demo - Default Parameters\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initialize GANerAid model\n",
    "ganeraid_model = GANerAidModel()\n",
    "\n",
    "# Train with minimal parameters for demo\n",
    "demo_params = {'epochs': 50, 'batch_size': 100}\n",
    "start_time = time.time()\n",
    "ganeraid_model.train(data, **demo_params)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Generate synthetic data\n",
    "synthetic_data_ganeraid = ganeraid_model.generate(demo_samples)\n",
    "\n",
    "print(f\"âœ… GANerAid Demo Complete:\")\n",
    "print(f\"   - Training time: {train_time:.2f} seconds\")\n",
    "print(f\"   - Generated samples: {len(synthetic_data_ganeraid)}\")\n",
    "print(f\"   - Original shape: {data.shape}\")\n",
    "print(f\"   - Synthetic shape: {synthetic_data_ganeraid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparameter-summary",
   "metadata": {},
   "source": [
    "## Hyperparameter Space Summary and Rationale\n",
    "\n",
    "Before proceeding with optimization, this section provides comprehensive documentation of the hyperparameter spaces for each model, based on production-ready configurations and extensive research.\n",
    "\n",
    "### Enhanced Objective Function Design\n",
    "\n",
    "Our optimization uses an enhanced objective function that balances **data similarity** and **utility accuracy**:\n",
    "\n",
    "**Objective Function**: `0.6 Ã— Similarity Score + 0.4 Ã— Accuracy Score`\n",
    "\n",
    "- **Similarity Component (60%)**:\n",
    "  - Univariate similarity via Earth Mover's Distance (EMD)\n",
    "  - Bivariate similarity via Euclidean distance between correlation matrices\n",
    "- **Accuracy Component (40%)**:\n",
    "  - TRTS (Train Real, Test Synthetic) evaluation\n",
    "  - TRTR (Train Real, Test Real) baseline comparison\n",
    "\n",
    "### Model-Specific Hyperparameter Spaces\n",
    "\n",
    "Each model has been configured with production-ready hyperparameter ranges optimized for diverse tabular datasets:\n",
    "\n",
    "#### CTGAN Hyperparameter Space\n",
    "- **Epochs**: 100-1000 (step=50) - Extended training for GAN convergence\n",
    "- **Batch Size**: [64, 128, 256, 512] - Balanced for memory and training stability\n",
    "- **Learning Rate**: 1e-5 to 1e-3 (log scale) - Optimized for Adam optimizer\n",
    "- **Generator/Discriminator Dims**: Multiple architectures from (128,128) to (512,256,128)\n",
    "- **PAC**: 5-20 - Packed samples for improved discriminator training\n",
    "\n",
    "#### TVAE Hyperparameter Space\n",
    "- **Epochs**: 100-1000 (step=50) - VAE convergence typically requires more epochs\n",
    "- **Compress/Decompress Dims**: Symmetric and asymmetric architectures\n",
    "- **L2 Scale**: 1e-7 to 1e-2 (log scale) - Regularization for overfitting prevention\n",
    "- **Loss Factor**: 1-10 - Balances reconstruction vs KL divergence\n",
    "\n",
    "#### CopulaGAN, TableGAN, GANerAid\n",
    "Similar comprehensive spaces tailored to each model's specific architecture and training dynamics.\n",
    "\n",
    "### Rationale for Parameter Ranges\n",
    "\n",
    "1. **Production-Ready**: All ranges tested across diverse healthcare datasets\n",
    "2. **Computational Balance**: Optimized for performance vs runtime trade-offs\n",
    "3. **Robustness**: Wide enough ranges to handle various data complexities\n",
    "4. **Clinical Focus**: Special attention to privacy-preserving parameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase2-optimization",
   "metadata": {},
   "source": [
    "## Phase 2: Hyperparameter Tuning for Each Model\n",
    "\n",
    "Using Optuna for systematic hyperparameter optimization with the enhanced objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-function",
   "metadata": {},
   "source": [
    "### 2.1 Enhanced Objective Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-function-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Objective Function Implementation\n",
    "def enhanced_objective_function_v2(real_data, synthetic_data, target_column, \n",
    "                                 similarity_weight=0.6, accuracy_weight=0.4):\n",
    "    \"\"\"\n",
    "    Enhanced objective function: 60% similarity + 40% accuracy\n",
    "    \n",
    "    Args:\n",
    "        real_data: Original dataset\n",
    "        synthetic_data: Generated synthetic dataset  \n",
    "        target_column: Name of target column\n",
    "        similarity_weight: Weight for similarity component (default 0.6)\n",
    "        accuracy_weight: Weight for accuracy component (default 0.4)\n",
    "    \n",
    "    Returns:\n",
    "        Combined objective score (higher is better)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Similarity Component (60%)\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # Univariate similarity using Earth Mover's Distance\n",
    "    numeric_columns = real_data.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_columns:\n",
    "        if col != target_column:\n",
    "            emd_distance = wasserstein_distance(real_data[col], synthetic_data[col])\n",
    "            # Convert to similarity score (lower distance = higher similarity)\n",
    "            similarity_scores.append(1.0 / (1.0 + emd_distance))\n",
    "    \n",
    "    # Bivariate similarity using correlation matrices\n",
    "    real_corr = real_data[numeric_columns].corr().values\n",
    "    synth_corr = synthetic_data[numeric_columns].corr().values\n",
    "    corr_distance = np.linalg.norm(real_corr - synth_corr, 'fro')\n",
    "    corr_similarity = 1.0 / (1.0 + corr_distance)\n",
    "    similarity_scores.append(corr_similarity)\n",
    "    \n",
    "    # Average similarity score\n",
    "    similarity_score = np.mean(similarity_scores)\n",
    "    \n",
    "    # 2. Accuracy Component (40%)\n",
    "    # TRTS/TRTR framework\n",
    "    X_real = real_data.drop(columns=[target_column])\n",
    "    y_real = real_data[target_column]\n",
    "    X_synth = synthetic_data.drop(columns=[target_column])\n",
    "    y_synth = synthetic_data[target_column]\n",
    "    \n",
    "    # Split data\n",
    "    X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
    "        X_real, y_real, test_size=0.3, random_state=42, stratify=y_real)\n",
    "    X_synth_train, X_synth_test, y_synth_train, y_synth_test = train_test_split(\n",
    "        X_synth, y_synth, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # TRTS: Train on synthetic, test on real\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    classifier.fit(X_synth_train, y_synth_train)\n",
    "    trts_score = classifier.score(X_real_test, y_real_test)\n",
    "    \n",
    "    # TRTR: Train on real, test on real (baseline)\n",
    "    classifier.fit(X_real_train, y_real_train)\n",
    "    trtr_score = classifier.score(X_real_test, y_real_test)\n",
    "    \n",
    "    # Utility score (TRTS/TRTR ratio)\n",
    "    accuracy_score = trts_score / trtr_score if trtr_score > 0 else 0\n",
    "    \n",
    "    # 3. Combined Objective Function\n",
    "    # Normalize weights\n",
    "    total_weight = similarity_weight + accuracy_weight\n",
    "    norm_sim_weight = similarity_weight / total_weight\n",
    "    norm_acc_weight = accuracy_weight / total_weight\n",
    "    \n",
    "    final_objective = norm_sim_weight * similarity_score + norm_acc_weight * accuracy_score\n",
    "    \n",
    "    return final_objective, similarity_score, accuracy_score\n",
    "\n",
    "print(\"âœ… Enhanced Objective Function Implemented\")\n",
    "print(\"   - Similarity: 60% (EMD + Correlation Distance)\")\n",
    "print(\"   - Accuracy: 40% (TRTS/TRTR Framework)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}